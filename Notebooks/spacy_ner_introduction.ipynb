{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Named Entity Recognition with spaCy \n",
    "\n",
    "This notebook helps you access the Named Entity Recognition (NER) tools in the spaCy Python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "* [Premise](#section-premise)\n",
    "* [Requirements](#section-requirements) \n",
    "* [Data Preparation](#section-datapreparation)\n",
    "* [Named Entity Recognition](#section-ner)\n",
    "  * [Looking for Named Entities](#section-nes)\n",
    "  * [Categorising Named Entities](#section-categories) \n",
    "  * [Named Entities as Multi-Word Expressions](#section-mwes)\n",
    "  * [Improving the spaCy processing](#section-improvingspacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premise <a class=\"anchor\" id=\"section-premise\"></a>\n",
    "*This section explains purpose of this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to introduce you to the spaCy Python package and show you how toi use it to recognise certain proper noun phrases or \"Named Entities\" in electronic text. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "It will teach you how to\n",
    "<ul>\n",
    "    <li>use the spaCy library to identify and classify Named Entities (NEs)</li>\n",
    "    <li>identify multi-word expressions (MWE) that are NEs</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements <a class=\"anchor\" id=\"section-requirements\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This notebook uses various Python libraries. Most will come with your Python installation, but the following are crucial:\n",
    "<ul>\n",
    "    <li> pandas</li> \n",
    "    <li> numpy</li> \n",
    "    <li> spacy</li> \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will load the required libraries into the notebook. If your computer is unable to do so, you may have to add an install line for the required package or seek technical advice.\n",
    "\n",
    "For example:\n",
    "<pre><code>import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TO DO] UPDATE\n",
    "# Many of these are probably not needed.\n",
    "\n",
    "import os\n",
    "#from pickle import NONE\n",
    "#import nltk\n",
    "#import csv\n",
    "#import time\n",
    "#import urllib\n",
    "#import requests\n",
    "#import json\n",
    "#import math\n",
    "\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "# spaCy is used for a pipeline of NLP functions\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you can see as much of the output as possible within the Jupyter Notebook screen\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation <a class=\"anchor\" id=\"section-datapreparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will use the text of *For the Term of His Natural Life* (*FtToHNL*), an 1874CE novel by Marcus Clarke that is in the public domain. Our copy was obtained via the [Gutenburg Project Australia](https://gutenberg.net.au/ebooks/e00016.txt) and is an unformatted textfile. We have slightly simplified it further by reducing it to only standard ASCII characters, replacing any accented characters with their unaccented forms and the British Pound Sterling symbol with the word pounds. \n",
    "\n",
    "The novel is divided into four books, each based in different regions of the world. You can start Chapter 3 of of the second book, which is titled *BOOK II.\\-\\-MACQUARIE HARBOUR.  1833*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to read the text from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading:  FtToHNL_BOOK_2_CHAPTER_3.txt\n"
     ]
    }
   ],
   "source": [
    "# This presumes that Notebooks/ is the current working directory  \n",
    "text_directory = os.path.normpath(\"../Texts/\")\n",
    "filename=\"FtToHNL_BOOK_2_CHAPTER_3.txt\"\n",
    "print(\"Reading: \", filename)\n",
    "\n",
    "# Set the specific path for the 'filename' \n",
    "text_location = os.path.normpath(os.path.join(text_directory, filename))\n",
    "text_filename = os.path.basename(text_location)\n",
    "\n",
    "# Read the text from the file\n",
    "text = open(text_location, encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no more than a long string of characters. So far, you have done no processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER III.\\n\\nA SOCIAL EVENING.\\n\\n\\n\\nIn the house of Major Vickers, Commandant of Macquarie Harbour,\\nthere was, on this evening of December 3rd, unusual gaiety.\\n\\nLieutenant Maurice Frere, late in command at Maria Island, had unexpectedly\\ncome down with news from head-quarters.  The Ladybird, Government schooner,\\nvisited the settlement on ordinary occasions twice a year, and such visits\\nwere looked forward to with no little eagerness by the settlers.\\nTo the convicts the arrival of the Ladybird mean'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 501 characters\n",
    "text[0:500] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition <a class=\"anchor\" id=\"section-ner\"></a>\n",
    "*This section provides tools on identifying named entities in textual data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for NEs <a class=\"anchor\" id=\"section-nes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entities (NEs) are proper noun phrases within text, like the names of places, people or organisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above text from Book 2 of FtToHNL, you can see there are the names of places, characters, and a ship.  While you could mannually extract them from the text, Natural Language Processing (NLP) technology allows this process to be semi-automated through software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various packages that can include Named Enity Recognition (NER) tools, e.g., the [Stanza CoreNLP](https://colab.research.google.com/github/stanfordnlp/stanza/blob/main/demo/Stanza_CoreNLP_Interface.ipynb), the Stanford NER, and the spaCy library. They often combine machine learning and a rule-based system to identify NEs and classify them into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, you will be using the [spaCy NER](https://spacy.io/usage/linguistic-features#named-entities).  This is available as part of the spaCy Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy allows you to load a [language model](https://spacy.io/models/en#en_core_web_sm) that has been trained on various examples of the language of interest. This training allows it to use statistical methods to evaluate the presence of various patterns in related texts that can be associated to linguistic behaviours.\n",
    "\n",
    "__[TO DO] Explain a language model *better* in one sentence.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy will use the model in various levels of natural language processing, that is called a processing pipeline. This pipeline includes dividing the text into individual tokens or terms, like words, values and punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The options for the spaCy pipeline include:\n",
    "    <p>&nbsp;</p>\n",
    "<table>\n",
    "    <tr><th>NAME</th>\t<th>COMPONENT</th>\t\t<th>\tDESCRIPTION</th>\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>tokenizer</strong></td><td>\tTokenizer</td><td>\tSegment text into tokens.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "\n",
    "<td><strong>tagger</strong></td><td>\tTagger</td><td>\tAssign part-of-speech tags.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "\n",
    "<td><strong>parser</strong></td><td>\tDependencyParser</td><td>\tAssign dependency labels.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "\n",
    "<td><strong>ner</strong></td><td>\tEntityRecognizer</td><td>\tDetect and label named entities.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "\n",
    "<td><strong>lemmatizer</strong></td><td>\tLemmatizer</td><td>\tAssign base forms.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "\n",
    "<td><strong>textcat</strong></td><td>\tTextCategorizer</td><td>\tAssign document labels.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "\n",
    "<td><strong>custom</strong></td><td>\tcustom components</td><td>\tAssign custom attributes, methods or properties.</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \n",
    "   A full explanation can be found at <a href=\"https://spacy.io/usage/processing-pipelines\">https://spacy.io/usage/processing-pipelines</a>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spaCy Language Procesing Pipeline](./spaCy_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, by default the spaCy pipeline contains the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tagger', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Output the processes in the current pipeline\n",
    "print(\"Pipeline:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you send the FtToHNL text to the spaCy model, it will be processed by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHAPTER III.\n",
       "\n",
       "A SOCIAL EVENING.\n",
       "\n",
       "\n",
       "\n",
       "In the house of Major Vickers, Commandant of Macquarie Harbour,\n",
       "there was, on this evening of December 3rd, unusual gaiety.\n",
       "\n",
       "Lieutenant Maurice Frere, late in command at Maria Island, had unexpectedly\n",
       "come down with news from head-quarters.  The Ladybird, Government schooner,\n",
       "visited the settlement on ordinary occasions twice a year, and such visits\n",
       "were looked forward to with no little eagerness by the settlers.\n",
       "To the convicts the arrival of the Ladybird mean"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the first 501 characters of the text using the model and pipeline\n",
    "doc = nlp(text[0:500])\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not look very different to what we read from the file, but the output from the pipeline is now available in the output structure of the spaCy model. Each word is regarded as a token and each token has various linguistic features, based on the lexical and grammatical aspects that were identified by the pipeline, especially the parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "From <a href=\"https://spacy.io/usage/linguistic-features\">https://spacy.io/usage/linguistic-features</a>:\n",
    "        <ul><li> <strong>Text:</strong> The original token text.</li>\n",
    "<li> <strong>Dep:</strong> The syntactic relation connecting child to head.</li>\n",
    "<li> <strong>Head text:</strong> The original text of the token head.</li>\n",
    "<li> <strong>Head POS:</strong> The part-of-speech tag of the token head.</li>\n",
    "<li> <strong>Children:</strong> The immediate syntactic dependents of the token.</li>\n",
    "    </ul>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  -  \n",
      "   Dep:  prep \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  [house]\n",
      "the  -  \n",
      "   Dep:  det \n",
      "   Head:  house \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "house  -  \n",
      "   Dep:  pobj \n",
      "   Head:  In \n",
      "   Pos:  ADP \n",
      "   Child:  [the, of]\n",
      "of  -  \n",
      "   Dep:  prep \n",
      "   Head:  house \n",
      "   Pos:  NOUN \n",
      "   Child:  [Vickers]\n",
      "Major  -  \n",
      "   Dep:  compound \n",
      "   Head:  Vickers \n",
      "   Pos:  PROPN \n",
      "   Child:  []\n",
      "Vickers  -  \n",
      "   Dep:  pobj \n",
      "   Head:  of \n",
      "   Pos:  ADP \n",
      "   Child:  [Major, ,, Commandant]\n",
      ",  -  \n",
      "   Dep:  punct \n",
      "   Head:  Vickers \n",
      "   Pos:  PROPN \n",
      "   Child:  []\n",
      "Commandant  -  \n",
      "   Dep:  appos \n",
      "   Head:  Vickers \n",
      "   Pos:  PROPN \n",
      "   Child:  [of]\n",
      "of  -  \n",
      "   Dep:  prep \n",
      "   Head:  Commandant \n",
      "   Pos:  PROPN \n",
      "   Child:  [Harbour]\n",
      "Macquarie  -  \n",
      "   Dep:  compound \n",
      "   Head:  Harbour \n",
      "   Pos:  PROPN \n",
      "   Child:  []\n",
      "Harbour  -  \n",
      "   Dep:  pobj \n",
      "   Head:  of \n",
      "   Pos:  ADP \n",
      "   Child:  [Macquarie]\n",
      ",  -  \n",
      "   Dep:  punct \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  [\n",
      "]\n",
      "\n",
      "  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:  PUNCT \n",
      "   Child:  []\n",
      "there  -  \n",
      "   Dep:  expl \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  []\n",
      "was  -  \n",
      "   Dep:  ROOT \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  [In, ,, there, ,, on, gaiety, .]\n",
      ",  -  \n",
      "   Dep:  punct \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  []\n",
      "on  -  \n",
      "   Dep:  prep \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  [evening]\n",
      "this  -  \n",
      "   Dep:  det \n",
      "   Head:  evening \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "evening  -  \n",
      "   Dep:  pobj \n",
      "   Head:  on \n",
      "   Pos:  ADP \n",
      "   Child:  [this, of]\n",
      "of  -  \n",
      "   Dep:  prep \n",
      "   Head:  evening \n",
      "   Pos:  NOUN \n",
      "   Child:  [3rd]\n",
      "December  -  \n",
      "   Dep:  compound \n",
      "   Head:  3rd \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "3rd  -  \n",
      "   Dep:  pobj \n",
      "   Head:  of \n",
      "   Pos:  ADP \n",
      "   Child:  [December]\n",
      ",  -  \n",
      "   Dep:  punct \n",
      "   Head:  gaiety \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "unusual  -  \n",
      "   Dep:  amod \n",
      "   Head:  gaiety \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "gaiety  -  \n",
      "   Dep:  attr \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  [,, unusual]\n",
      ".  -  \n",
      "   Dep:  punct \n",
      "   Head:  was \n",
      "   Pos:  AUX \n",
      "   Child:  [\n",
      "\n",
      "]\n",
      "\n",
      "\n",
      "  -  \n",
      "   Dep:   \n",
      "   Head:  . \n",
      "   Pos:  PUNCT \n",
      "   Child:  []\n",
      "Lieutenant  -  \n",
      "   Dep:  compound \n",
      "   Head:  Maurice \n",
      "   Pos:  PROPN \n",
      "   Child:  []\n",
      "Maurice  -  \n",
      "   Dep:  compound \n",
      "   Head:  Frere \n",
      "   Pos:  PROPN \n",
      "   Child:  [Lieutenant]\n",
      "Frere  -  \n",
      "   Dep:  nsubj \n",
      "   Head:  come \n",
      "   Pos:  VERB \n",
      "   Child:  [Maurice]\n",
      ",  -  \n",
      "   Dep:  punct \n",
      "   Head:  had \n",
      "   Pos:  AUX \n",
      "   Child:  []\n",
      "late  -  \n",
      "   Dep:  advmod \n",
      "   Head:  at \n",
      "   Pos:  ADP \n",
      "   Child:  [in]\n",
      "in  -  \n",
      "   Dep:  prep \n",
      "   Head:  late \n",
      "   Pos:  ADV \n",
      "   Child:  [command]\n",
      "command  -  \n",
      "   Dep:  pobj \n",
      "   Head:  in \n",
      "   Pos:  ADP \n",
      "   Child:  []\n",
      "at  -  \n",
      "   Dep:  prep \n",
      "   Head:  had \n",
      "   Pos:  AUX \n",
      "   Child:  [late, Island]\n",
      "Maria  -  \n",
      "   Dep:  compound \n",
      "   Head:  Island \n",
      "   Pos:  PROPN \n",
      "   Child:  []\n",
      "Island  -  \n",
      "   Dep:  pobj \n",
      "   Head:  at \n",
      "   Pos:  ADP \n",
      "   Child:  [Maria]\n",
      ",  -  \n",
      "   Dep:  punct \n",
      "   Head:  had \n",
      "   Pos:  AUX \n",
      "   Child:  []\n",
      "had  -  \n",
      "   Dep:  aux \n",
      "   Head:  come \n",
      "   Pos:  VERB \n",
      "   Child:  [,, at, ,, unexpectedly]\n",
      "unexpectedly  -  \n",
      "   Dep:  advmod \n",
      "   Head:  had \n",
      "   Pos:  AUX \n",
      "   Child:  [\n",
      "]\n",
      "\n",
      "  -  \n",
      "   Dep:   \n",
      "   Head:  unexpectedly \n",
      "   Pos:  ADV \n",
      "   Child:  []\n",
      "come  -  \n",
      "   Dep:  ROOT \n",
      "   Head:  come \n",
      "   Pos:  VERB \n",
      "   Child:  [Frere, had, down, with, .]\n",
      "down  -  \n",
      "   Dep:  prt \n",
      "   Head:  come \n",
      "   Pos:  VERB \n",
      "   Child:  []\n",
      "with  -  \n",
      "   Dep:  prep \n",
      "   Head:  come \n",
      "   Pos:  VERB \n",
      "   Child:  [news]\n",
      "news  -  \n",
      "   Dep:  pobj \n",
      "   Head:  with \n",
      "   Pos:  ADP \n",
      "   Child:  [from]\n",
      "from  -  \n",
      "   Dep:  prep \n",
      "   Head:  news \n",
      "   Pos:  NOUN \n",
      "   Child:  [quarters]\n",
      "head  -  \n",
      "   Dep:  compound \n",
      "   Head:  quarters \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "-  -  \n",
      "   Dep:  punct \n",
      "   Head:  quarters \n",
      "   Pos:  NOUN \n",
      "   Child:  []\n",
      "quarters  -  \n",
      "   Dep:  pobj \n",
      "   Head:  from \n",
      "   Pos:  ADP \n",
      "   Child:  [head, -]\n",
      ".  -  \n",
      "   Dep:  punct \n",
      "   Head:  come \n",
      "   Pos:  VERB \n",
      "   Child:  [ ]\n"
     ]
    }
   ],
   "source": [
    "# For each token in the first two sentences,\n",
    "for token in doc[9:59]:\n",
    "    # print the linguistic features of the token identified by the pipeline\n",
    "    print(token.text,\" - \", \n",
    "          \"\\n   Dep: \",token.dep_,       \n",
    "          \"\\n   Head: \",token.head.text, \n",
    "          \"\\n   Pos: \",token.head.pos_,  \n",
    "          \"\\n   Child: \",[child for child in token.children]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you might not want some of this pipeline processing as it may not be beneficial to your analysis. Any unneeded processing will also slow the system down and place a greater demand on the memory. This is particularly true of the parser. Luckily, it is easy to stipulate what you want excluded from the spaCy pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first 501 characters of the text with a shortened pipeline\n",
    "doc=nlp(text[0:500], disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  -  \n",
      "   Dep:   \n",
      "   Head:  In \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "the  -  \n",
      "   Dep:   \n",
      "   Head:  the \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "house  -  \n",
      "   Dep:   \n",
      "   Head:  house \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "of  -  \n",
      "   Dep:   \n",
      "   Head:  of \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Major  -  \n",
      "   Dep:   \n",
      "   Head:  Major \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Vickers  -  \n",
      "   Dep:   \n",
      "   Head:  Vickers \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ",  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Commandant  -  \n",
      "   Dep:   \n",
      "   Head:  Commandant \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "of  -  \n",
      "   Dep:   \n",
      "   Head:  of \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Macquarie  -  \n",
      "   Dep:   \n",
      "   Head:  Macquarie \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Harbour  -  \n",
      "   Dep:   \n",
      "   Head:  Harbour \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ",  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "\n",
      "  -  \n",
      "   Dep:   \n",
      "   Head:  \n",
      " \n",
      "   Pos:  SPACE \n",
      "   Child:  []\n",
      "there  -  \n",
      "   Dep:   \n",
      "   Head:  there \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "was  -  \n",
      "   Dep:   \n",
      "   Head:  was \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ",  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "on  -  \n",
      "   Dep:   \n",
      "   Head:  on \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "this  -  \n",
      "   Dep:   \n",
      "   Head:  this \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "evening  -  \n",
      "   Dep:   \n",
      "   Head:  evening \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "of  -  \n",
      "   Dep:   \n",
      "   Head:  of \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "December  -  \n",
      "   Dep:   \n",
      "   Head:  December \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "3rd  -  \n",
      "   Dep:   \n",
      "   Head:  3rd \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ",  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "unusual  -  \n",
      "   Dep:   \n",
      "   Head:  unusual \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "gaiety  -  \n",
      "   Dep:   \n",
      "   Head:  gaiety \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ".  -  \n",
      "   Dep:   \n",
      "   Head:  . \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "\n",
      "\n",
      "  -  \n",
      "   Dep:   \n",
      "   Head:  \n",
      "\n",
      " \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Lieutenant  -  \n",
      "   Dep:   \n",
      "   Head:  Lieutenant \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Maurice  -  \n",
      "   Dep:   \n",
      "   Head:  Maurice \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Frere  -  \n",
      "   Dep:   \n",
      "   Head:  Frere \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ",  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "late  -  \n",
      "   Dep:   \n",
      "   Head:  late \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "in  -  \n",
      "   Dep:   \n",
      "   Head:  in \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "command  -  \n",
      "   Dep:   \n",
      "   Head:  command \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "at  -  \n",
      "   Dep:   \n",
      "   Head:  at \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Maria  -  \n",
      "   Dep:   \n",
      "   Head:  Maria \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "Island  -  \n",
      "   Dep:   \n",
      "   Head:  Island \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ",  -  \n",
      "   Dep:   \n",
      "   Head:  , \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "had  -  \n",
      "   Dep:   \n",
      "   Head:  had \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "unexpectedly  -  \n",
      "   Dep:   \n",
      "   Head:  unexpectedly \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "\n",
      "  -  \n",
      "   Dep:   \n",
      "   Head:  \n",
      " \n",
      "   Pos:  SPACE \n",
      "   Child:  []\n",
      "come  -  \n",
      "   Dep:   \n",
      "   Head:  come \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "down  -  \n",
      "   Dep:   \n",
      "   Head:  down \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "with  -  \n",
      "   Dep:   \n",
      "   Head:  with \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "news  -  \n",
      "   Dep:   \n",
      "   Head:  news \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "from  -  \n",
      "   Dep:   \n",
      "   Head:  from \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "head  -  \n",
      "   Dep:   \n",
      "   Head:  head \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "-  -  \n",
      "   Dep:   \n",
      "   Head:  - \n",
      "   Pos:   \n",
      "   Child:  []\n",
      "quarters  -  \n",
      "   Dep:   \n",
      "   Head:  quarters \n",
      "   Pos:   \n",
      "   Child:  []\n",
      ".  -  \n",
      "   Dep:   \n",
      "   Head:  . \n",
      "   Pos:   \n",
      "   Child:  []\n"
     ]
    }
   ],
   "source": [
    "# For each token in the first two sentences, \n",
    "for token in doc[9:59]:\n",
    "    # print the linguistic features of the tokenidentified by the shorter pipeline\n",
    "    print(token.text,\" - \", \n",
    "          \"\\n   Dep: \",token.dep_,        \n",
    "          \"\\n   Head: \",token.head.text,  \n",
    "          \"\\n   Pos: \",token.head.pos_,   \n",
    "          \"\\n   Child: \",[child for child in token.children])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, for this notebook what you are interested in is [spaCy's NER](https://spacy.io/usage/linguistic-features#named-entities). Any text sent down the pipeline with the NER will get a list of entities that have been found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vickers [PERSON]\n",
      "this evening [TIME]\n",
      "December 3rd [DATE]\n",
      "Maurice Frere [PERSON]\n",
      "Maria Island [LOC]\n",
      "Ladybird [ORG]\n"
     ]
    }
   ],
   "source": [
    "# For each Named Entity recognised by the NER,\n",
    "for entity in doc.ents:\n",
    "    # output the relevant tokens and NE category \n",
    "    print(entity.text+\" [\"+entity.label_+\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorising Named Entities <a class=\"anchor\" id=\"section-categories\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each entity is labelled with a category. The categories are defined by the model as it is trained to recognise them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    The NER categories classified by this spaCy model include:\n",
    "   <ul>\n",
    "       <li><strong>CARDINAL:</strong> Numerals that do not fall under another type</li>\n",
    "<li><strong>DATE:</strong> Absolute or relative dates or periods</li>\n",
    "<li><strong>EVENT:</strong> Named hurricanes, battles, wars, sports events, etc.</li>\n",
    "<li><strong>FAC:</strong> Buildings, airports, highways, bridges, etc.</li>\n",
    "<li><strong>GPE:</strong> Countries, cities, states</li>\n",
    "<li><strong>LANGUAGE:</strong> Any named language</li>\n",
    "<li><strong>LAW:</strong> Named documents made into laws.</li>\n",
    "<li><strong>LOC:</strong> Non-GPE locations, mountain ranges, bodies of water</li>\n",
    "<li><strong>MONEY:</strong> Monetary values, including unit</li>\n",
    "<li><strong>NORP:</strong> Nationalities or religious or political groups</li>\n",
    "<li><strong>ORDINAL:</strong> \"first\", \"second\", etc.</li>\n",
    "<li><strong>ORG:</strong> Companies, agencies, institutions, etc.</li>\n",
    "<li><strong>PERCENT:</strong> Percentage, including \"%\"</li>\n",
    "<li><strong>PERSON:</strong> People, including fictional</li>\n",
    "<li><strong>PRODUCT:</strong> Objects, vehicles, foods, etc. (not services)</li>\n",
    "<li><strong>QUANTITY:</strong> Measurements, as of weight or distance</li>\n",
    "<li><strong>TIME:</strong> Times smaller than a day</li>\n",
    "<li><strong>WORK_OF_ART:</strong> Titles of books, songs, etc.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These categories can be very helpful when you are trying to identify certain types of NEs. However, they are not perfect. Because the NER is based on the language model, words are given categories based on what the language model has seen in the training data. This means that the same NE can be given different categories, dependent on the linguistic context in which it appears. It should also be noted that spaCy's NER only labels each NE with one category and does not normally provide any measure of how certain it is about that category. Other NLP systems will have similar NE categories, but there is no universal ontology. Some are more fine-grained than others. If you need even more fine-grained or alternate categories in spaCy, you will have to train and use a suitable language model or add some post-processing, which will be briefly discussed [later in this notebook](#section-improvingspacy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities as Multi-Word Expressions <a class=\"anchor\" id=\"section-mwes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that some of the NEs recognised by spaCy in the text include more than one word. The ability to recognise Multi-Word Expressions (MWEs) as NEs is important, as is understanding the context of word usage. Luckily, the data for the entities includes the character position for the start and the end of the NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vickers (57,64) [PERSON]\n",
      "this evening (113,125) [TIME]\n",
      "December 3rd (129,141) [DATE]\n",
      "Maurice Frere (171,184) [PERSON]\n",
      "Maria Island (205,217) [LOC]\n",
      "Ladybird (487,495) [ORG]\n"
     ]
    }
   ],
   "source": [
    "# For each Named Entity recognised by the NER,\n",
    "for entity in doc.ents:\n",
    "    # output the start and end characters for the relevant tokens\n",
    "    print(entity.text, \"(\"+str(entity.start_char)+\",\"+str(entity.end_char)+\") [\"+entity.label_+\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each token will also have a value that indicates whether it is part of an NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [  ]\n",
      "the [  ]\n",
      "house [  ]\n",
      "of [  ]\n",
      "Major [  ]\n",
      "Vickers [ PERSON ]\n",
      ", [  ]\n",
      "Commandant [  ]\n",
      "of [  ]\n",
      "Macquarie [  ]\n",
      "Harbour [  ]\n",
      ", [  ]\n",
      "\n",
      " [  ]\n",
      "there [  ]\n",
      "was [  ]\n",
      ", [  ]\n",
      "on [  ]\n",
      "this [ TIME ]\n",
      "evening [ TIME ]\n",
      "of [  ]\n",
      "December [ DATE ]\n",
      "3rd [ DATE ]\n",
      ", [  ]\n",
      "unusual [  ]\n",
      "gaiety [  ]\n",
      ". [  ]\n",
      "\n",
      "\n",
      " [  ]\n",
      "Lieutenant [  ]\n",
      "Maurice [ PERSON ]\n",
      "Frere [ PERSON ]\n",
      ", [  ]\n",
      "late [  ]\n",
      "in [  ]\n",
      "command [  ]\n",
      "at [  ]\n",
      "Maria [ LOC ]\n",
      "Island [ LOC ]\n",
      ", [  ]\n",
      "had [  ]\n",
      "unexpectedly [  ]\n",
      "\n",
      " [  ]\n",
      "come [  ]\n",
      "down [  ]\n",
      "with [  ]\n",
      "news [  ]\n",
      "from [  ]\n",
      "head [  ]\n",
      "- [  ]\n",
      "quarters [  ]\n",
      ". [  ]\n"
     ]
    }
   ],
   "source": [
    "# For each token in the first two sentences\n",
    "for token in doc[9:59]:\n",
    "    # output whether it has an NE category\n",
    "    print(token.text+\" [\"+token.ent_type_+\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contextual information is very helpful as it helps you evaluate the scope of terms regarded as a part of an NE and whether they are appropriate, given the linguistic use of the terms. For instance, in your example sentences, you can see that both of the PERSON NEs are directly preceded by military titles, e.g., _Major Vickers_ and _Lieutenant Maurice Frere_. It also shows that _Maria_ is not regarded as a Person NE because it is part of a LOC NE. This is one of the consequences of spaCy only labelling one NE category per token. If a token is regarded to be part of a MWE, then this subsumes any possible categories it may be regarded as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the spaCy processing  <a class=\"anchor\" id=\"section-improvingspacy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have also recognised that the spaCy NER didn't recognise that _Macquarie Harbour_ was a Named Entity. This might have happened if the training data for the language model you used didn't have any example text that included the words _Macquarie_ or _harbour_, especially as part of a proper noun phrase. The most obvious way to correct this is to train a new model that does have such examples. It is beyond the scope of this notebook to discuss but [spaCy has various guides](https://spacy.io/usage/training) on how this can be done, especially for NER.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to train models, then you can always set up some post-processing Python code to add some new NEs or change their categories. This is a good option if you don't have a wide range of changes to make, or if the linguistic contexts in which it would apply are very specific, e.g., only for a small closed set of words or distinct grammatical strutures. Again, this is beyond the scope of this workshop, as it requires an understanding of the [spaCy IOB and BILUO schema](https://spacy.io/usage/linguistic-features#accessing-ner) if you want to [set your own entities](https://spacy.io/usage/linguistic-features#setting-entities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as previously mentioned, some of the natural language processing in the spaCy pipeline can be resource-hungry, taking up CPU usage and/or memory. For this reason, if you are wanting to process a lot of data, like a lot of documents or sentences, you might be better processing them in batches. This will split up the processing by [piping the data to the pipeline](https://spacy.io/usage/processing-pipelines#processing) as a stream rather than processing it altogether at each stage. This is relatively easy to do but it does change some of the data structures of some output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[TO DO] Shift the below discussions back to the main workshop notebook__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[TO DO] Run through a single chapter (variable: text) before doing the entire collection?\n",
    "    This will allow all NEs to be shown, then the filter be introduced.\n",
    "    This will put it more on topic.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER III.\\n\\nA SOCIAL EVENING.\\n\\n\\n\\nIn the house of Major Vickers, Commandant of Macquarie Harbour,\\nthere was, on this evening of December 3rd, unusual gaiety.\\n\\nLieutenant Maurice Frere, late in command at Maria Island, had unexpectedly\\ncome down with news from head-quarters.  The Ladybird, Government schooner,\\nvisited the settlement on ordinary occasions twice a year, and such visits\\nwere looked forward to with no little eagerness by the settlers.\\nTo the convicts the arrival of the Ladybird mean'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1\t\tVickers                       \tPERSON\n",
      "    2\t\tthis evening                  \tTIME\n",
      "    3\t\tDecember 3rd                  \tDATE\n",
      "    4\t\tMaurice Frere                 \tPERSON\n",
      "    5\t\tMaria Island                  \tLOC\n",
      "    6\t\tLadybird                      \tORG\n",
      "    7\t\tLadybird                      \tPERSON\n",
      "    8\t\tLadybird                      \tORG\n",
      "    9\t\tTom                           \tPERSON\n",
      "   10\t\tDick                          \tPERSON\n",
      "   11\t\tHarry                         \tPERSON\n",
      "   12\t\tbush                          \tPERSON\n",
      "   13\t\tJack                          \tPERSON\n",
      "   14\t\tTown Gaol                     \tPERSON\n",
      "   15\t\tLadybird                      \tORG\n",
      "   16\t\tone                           \tCARDINAL\n",
      "   17\t\tCommandant                    \tORG\n",
      "   18\t\tVickers                       \tPERSON\n",
      "   19\t\tArthur                        \tPERSON\n",
      "   20\t\tHobart Town                   \tORG\n",
      "   21\t\tArthur                        \tPERSON\n",
      "   22\t\tTasman                        \tPERSON\n",
      "   23\t\tPeninsula                     \tLOC\n",
      "   24\t\tPort Arthur                   \tORG\n",
      "   25\t\tMaurice Frere                 \tPERSON\n",
      "   26\t\tVickers                       \tORG\n",
      "   27\t\tMacquarie Harbour             \tORG\n",
      "   28\t\tLieutenant Frere              \tPRODUCT\n",
      "   29\t\tNine years before             \tDATE\n",
      "   30\t\tArthur                        \tPERSON\n",
      "   31\t\tHonduras                      \tGPE\n",
      "   32\t\tSorrell                       \tPERSON\n",
      "   33\t\tfirst                         \tORDINAL\n",
      "   34\t\tArthur                        \tORG\n",
      "   35\t\tArthur                        \tPERSON\n",
      "   36\t\tthe 2nd November, 1829        \tDATE\n",
      "   37\t\tthirty-eight                  \tCARDINAL\n",
      "   38\t\tfifty-six                     \tQUANTITY\n",
      "   39\t\tthe 26th of September the same year\tDATE\n",
      "   40\t\tseven hundred and forty-five  \tQUANTITY\n",
      "   41\t\tSundays                       \tDATE\n",
      "   42\t\ttwenty                        \tCARDINAL\n",
      "   43\t\tSeven                         \tCARDINAL\n",
      "   44\t\t1826                          \tDATE\n",
      "   45\t\tHobart Town                   \tORG\n",
      "   46\t\tfirst                         \tORDINAL\n",
      "   47\t\tSaturday                      \tDATE\n",
      "   48\t\tsecond                        \tORDINAL\n",
      "   49\t\tthird                         \tORDINAL\n",
      "   50\t\tSaturday                      \tDATE\n",
      "   51\t\tafternoon                     \tTIME\n",
      "   52\t\tfourth                        \tORDINAL\n",
      "   53\t\tfifth                         \tORDINAL\n",
      "   54\t\tsixth                         \tORDINAL\n",
      "   55\t\tseventh                       \tORDINAL\n",
      "   56\t\tMaria Island                  \tLOC\n",
      "   57\t\tHells Gates                   \tORG\n",
      "   58\t\tone year                      \tDATE\n",
      "   59\t\teighty-five                   \tCARDINAL\n",
      "   60\t\tonly thirty                   \tCARDINAL\n",
      "   61\t\ttwenty-seven                  \tCARDINAL\n",
      "   62\t\teight                         \tCARDINAL\n",
      "   63\t\tthree                         \tCARDINAL\n",
      "   64\t\ttwelve                        \tCARDINAL\n",
      "   65\t\t1822                          \tDATE\n",
      "   66\t\tone hundred and sixty-nine    \tCARDINAL\n",
      "   67\t\tone hundred and eighty-two    \tCARDINAL\n",
      "   68\t\ttwo thousand                  \tCARDINAL\n",
      "   69\t\tthe ten years                 \tDATE\n",
      "   70\t\tone hundred and twelve        \tCARDINAL\n",
      "   71\t\tsixty-two                     \tQUANTITY\n",
      "   72\t\tArthur                        \tORG\n",
      "   73\t\tMaurice Frere                 \tPERSON\n",
      "   74\t\tone                           \tCARDINAL\n",
      "   75\t\tThe six years                 \tDATE\n",
      "   76\t\tEngland                       \tGPE\n",
      "   77\t\tfive years'                   \tDATE\n",
      "   78\t\tMaria Island                  \tLOC\n",
      "   79\t\tVickers                       \tPERSON\n",
      "   80\t\tVickers                       \tORG\n",
      "   81\t\tVickers                       \tPERSON\n",
      "   82\t\tsix years                     \tDATE\n",
      "   83\t\tJohn                          \tPERSON\n",
      "   84\t\tFrere                         \tPERSON\n",
      "   85\t\tSylvia                        \tGPE\n",
      "   86\t\tHobart Town                   \tORG\n",
      "   87\t\tJohn                          \tPERSON\n",
      "   88\t\tSylvia                        \tPERSON\n",
      "   89\t\tVickers                       \tORG\n",
      "   90\t\tPurfoy                        \tPERSON\n",
      "   91\t\tVickers                       \tPERSON\n",
      "   92\t\tFrere                         \tPERSON\n",
      "   93\t\tVickers                       \tPERSON\n",
      "   94\t\tRex                           \tPERSON\n",
      "   95\t\tSylvia                        \tGPE\n",
      "   96\t\tJohn                          \tPERSON\n",
      "   97\t\tFrere                         \tPERSON\n",
      "   98\t\tthe six months                \tDATE\n",
      "   99\t\tHobart Town                   \tPRODUCT\n",
      "  100\t\tSylvia                        \tPERSON\n",
      "  101\t\tFrere                         \tPERSON\n",
      "  102\t\tPurfoy                        \tPERSON\n",
      "  103\t\tRex                           \tPERSON\n",
      "  104\t\tRex                           \tPERSON\n",
      "  105\t\tEngland                       \tGPE\n",
      "  106\t\tFrere                         \tPERSON\n",
      "  107\t\tNew Town                      \tGPE\n",
      "  108\t\tRex                           \tPERSON\n",
      "  109\t\tFrere                         \tPERSON\n",
      "  110\t\tLaunceston                    \tPERSON\n",
      "  111\t\tSydney                        \tPERSON\n",
      "  112\t\tRex                           \tPERSON\n",
      "  113\t\tPine                          \tPERSON\n",
      "  114\t\tSylvia                        \tPERSON\n",
      "  115\t\tJohn                          \tPERSON\n",
      "  116\t\tVickers                       \tORG\n",
      "  117\t\tverandah.-She                 \tORG\n",
      "  118\t\tVickers                       \tPERSON\n",
      "  119\t\tVickers                       \tORG\n",
      "  120\t\tone                           \tCARDINAL\n",
      "  121\t\ttwo                           \tCARDINAL\n",
      "  122\t\tGeorge                        \tPERSON\n",
      "  123\t\tVickers                       \tPERSON\n",
      "  124\t\tBarton                        \tPERSON\n",
      "  125\t\ttwelve                        \tCARDINAL\n",
      "  126\t\tmore than fifty               \tCARDINAL\n",
      "  127\t\tGrummet Island                \tLOC\n",
      "  128\t\tweek                          \tDATE\n",
      "  129\t\tGrummet                       \tLOC\n",
      "  130\t\ta month or so                 \tDATE\n",
      "  131\t\tMaria                         \tPERSON\n",
      "  132\t\tVickers                       \tPERSON\n",
      "  133\t\tMalabar                       \tGPE\n",
      "  134\t\tthe first year                \tDATE\n",
      "  135\t\tBarton                        \tPERSON\n",
      "  136\t\tDawes                         \tORG\n",
      "  137\t\t'29                           \tDATE\n",
      "  138\t\tSaid                          \tPERSON\n",
      "  139\t\tOsprey                        \tPERSON\n",
      "  140\t\tFrere                         \tPERSON\n",
      "  141\t\tfifty                         \tCARDINAL\n",
      "  142\t\tAbout six weeks ago           \tDATE\n",
      "  143\t\tGabbett                       \tPERSON\n",
      "  144\t\tGabbett                       \tPERSON\n",
      "  145\t\tthree                         \tCARDINAL\n",
      "  146\t\tVickers                       \tORG\n",
      "  147\t\tMacquarie Harbour             \tORG\n",
      "  148\t\tthe end of the month          \tDATE\n",
      "  149\t\tVickers                       \tORG\n",
      "  150\t\tFrere                         \tORG\n",
      "  151\t\tfirst                         \tORDINAL\n",
      "  152\t\tMaria                         \tPERSON\n",
      "  153\t\tGeorge                        \tPERSON\n",
      "  154\t\tVickers                       \tORG\n",
      "  155\t\tFrere                         \tPERSON\n",
      "  156\t\tArthur                        \tPERSON\n",
      "  157\t\tGeorge                        \tPERSON\n",
      "  158\t\tVickers                       \tORG\n",
      "  159\t\tBatten                        \tPERSON\n",
      "  160\t\tVickers                       \tPERSON\n",
      "  161\t\tLadybird                      \tPERSON\n",
      "  162\t\tVickers                       \tPERSON\n",
      "  163\t\tOsprey                        \tPERSON\n",
      "  164\t\tSylvia                        \tPERSON\n",
      "  165\t\tFrere                         \tPERSON\n",
      "  166\t\tLadybird                      \tORG\n",
      "  167\t\tOsprey                        \tPERSON\n",
      "  168\t\tVickers                       \tPERSON\n",
      "  169\t\tVickers                       \tORG\n",
      "  170\t\tFrere                         \tORG\n",
      "  171\t\tSylvia                        \tPERSON\n",
      "  172\t\tVickers                       \tORG\n",
      "  173\t\tSylvia                        \tPERSON\n",
      "  174\t\tMalabar                       \tGPE\n",
      "  175\t\tsome eleven years old         \tDATE\n",
      "  176\t\tFrere                         \tPERSON\n",
      "  177\t\tSylvia                        \tPERSON\n",
      "  178\t\tFrere                         \tPERSON\n",
      "  179\t\tFrere                         \tPERSON\n",
      "  180\t\tFrere                         \tPERSON\n",
      "  181\t\tSylvia                        \tGPE\n",
      "  182\t\tSylvia                        \tPERSON\n",
      "  183\t\tFrere                         \tORG\n",
      "  184\t\tLieutenant Frere              \tWORK_OF_ART\n",
      "  185\t\tSylvia                        \tGPE\n",
      "  186\t\tRufus Dawes                   \tWORK_OF_ART\n",
      "  187\t\tDanny                         \tPERSON\n",
      "  188\t\tDanny                         \tPERSON\n",
      "  189\t\tFrere                         \tPERSON\n",
      "  190\t\tVickers                       \tORG\n",
      "  191\t\tSylvia                        \tPERSON\n",
      "  192\t\tDanny                         \tPERSON\n",
      "  193\t\tSylvia                        \tPERSON\n",
      "  194\t\tLondon                        \tGPE\n",
      "  195\t\tLondon                        \tGPE\n",
      "  196\t\tDanny                         \tPERSON\n",
      "  197\t\tFancy Danny's                 \tPERSON\n",
      "  198\t\tPapa                          \tWORK_OF_ART\n",
      "  199\t\tWill Danny                    \tPERSON\n",
      "  200\t\tSylvia                        \tPERSON\n",
      "  201\t\thalf an hour                  \tTIME\n",
      "  202\t\tVickers                       \tORG\n",
      "  203\t\tVickers                       \tORG\n",
      "  204\t\tthree or four years           \tDATE\n",
      "  205\t\tSydney                        \tGPE\n",
      "  206\t\tEngland                       \tGPE\n",
      "  207\t\tTroke                         \tORG\n",
      "  208\t\tGabbett                       \tPERSON\n",
      "  209\t\tFrere                         \tPERSON\n",
      "  210\t\tGabbett                       \tPERSON\n",
      "  211\t\tsix weeks                     \tDATE\n",
      "  212\t\tTroke                         \tORG\n",
      "  213\t\tVickers                       \tORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "# document level\n",
    "entities = [(entity.text, entity.start_char, entity.end_char, entity.label_) for entity in doc.ents]\n",
    "    \n",
    "i=0 # entity counter\n",
    "# token level\n",
    "for entity in doc.ents:\n",
    "    print(\"{:5}\\t\\t{:30s}\\t{}\".format(i+1,entity.text, entity.label_))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[TO DO] Expand on this explanation with example context.\n",
    "Talk about the issue with _Van Diemen's_ versus _Van Diemen's Land_ (and _Tasman's Head_)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These categories are assigned according to the context in which the NE is used. For this reason, _Van Diemen's_ is considered an *ORG*, a *PERSON* and a *FAC*, depending on its linguistic context. Note also that _VAN DIEMEN'S LAND_ in the title of the chapter isn't recognised as a NE, probably due to its unconventional case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[TO DO] Expand on this explanation.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, not all of these NE are suitable for placenames, so you will need to make a list of what categories regularly contain placenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACENAME_CATEGORIES = [\"LOC\", \"GPE\", \"FAC\", \"ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
