{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATAP Notebook for the Geolocation project\n",
    "\n",
    "This notebook helps you access the Geolocation tools in a Python development environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "* [Premise](#section-premise)\n",
    "* [Requirements](#section-requirements) \n",
    "* [Data Preparation](#section-datapreparation)\n",
    "* [Named Entity Recognition](#section-ner)\n",
    " * [Look for NEs](#section-nes)\n",
    " * [Reviewing Candidate Placenames](#section-reviewplacenames)\n",
    "* [Finding Locations for Placenames](#section-findinglocs)\n",
    " * [Identifying States and Capitals](#section-statescapitals)\n",
    " * [Searching a Gazzetteer for Locations](#section-searchgazetteer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premise <a class=\"anchor\" id=\"section-premise\"></a>\n",
    "*This section explains the Geolocation project and tools.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Geolocation project relates to doctoral research done by [Fiannuala Morgan](https://finnoscarmorgan.github.io/) at the Australian National University. It uses software to identify placenames in archived historical texts, then compares them to data about known locations to identify where the placenames may be located. \n",
    "\n",
    "This notebook is designed to allow you to perform similar operations on textual documents.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "It will teach you how to\n",
    "<ul>\n",
    "    <li>use the spaCy library to identify and classify Named Entities (NEs)</li>\n",
    "    <li>identify multi-word expressions (MWE) that are NEs</li>\n",
    "    <li>search for spatial data about specific locations or places in gazetteers of such data</li>\n",
    "    <li>determine which locations are referred to by placenames, based on the context in which they are used in a text</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements <a class=\"anchor\" id=\"section-requirements\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This notebook uses various Python libraries. Most will come with your Python installation, but the following are crucial:\n",
    "<ul>\n",
    "    <li> pandas</li> \n",
    "    <li> json</li> \n",
    "    <li> nltk</li> \n",
    "    <li> geopandas</li> \n",
    "    <li> shapely  </li> \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: UPDATE\n",
    "# Many of these are probably not needed.\n",
    "\n",
    "import os\n",
    "from pickle import NONE\n",
    "import nltk\n",
    "import csv\n",
    "import time\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Geopandas is used to work with spatial data\n",
    "# If you have issues installing it on a MAcOS, \n",
    "# see https://stackoverflow.com/questions/71137617/error-installing-geopandas-in-python-on-mac-m1\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "# NLTK is used to work with textual data \n",
    "#from nltk.tag import StanfordNERTagger\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "# spaCy is used for a pipeline of NLP functions\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "\n",
    "# Shapely is used to work with geometric shapes\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Fuzzywuzzy is used for fuzzy searches\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# used for the checklist\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation <a class=\"anchor\" id=\"section-datapreparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also want to set up some directories for the import and output of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Declare the data directories\n",
    "## This presumes that Notebooks/ is the current working directory  \n",
    "text_directory = os.path.normpath(\"../Texts/\")\n",
    "csv_directory = os.path.normpath(\"../ner_output/\")\n",
    "reference_directory = os.path.normpath(\"../Data\")\n",
    "#maps_directory = os.path.normpath(\"../maps/\")\n",
    "\n",
    "## Create the data directories\n",
    "if not os.path.exists(text_directory):\n",
    "    os.makedirs(text_directory)\n",
    "if not os.path.exists(csv_directory):\n",
    "   os.makedirs(csv_directory)\n",
    "if not os.path.exists(reference_directory):\n",
    "   os.makedirs(reference_directory)\n",
    "\n",
    "#if not os.path.exists(maps_directory):\n",
    "#    os.makedirs(maps_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop, we will be examining the text of *For the Term of His Natural Life*, an 1874CE novel by Marcus Clarke that is in the public domain. Our copy was obtained via the [Gutenburg Project Australia](https://gutenberg.net.au/ebooks/e00016.txt). It is an unformatted textfile. We have slightly simplified it further by reducing it to only standard ASCII characters, replacing any accented characters with their unaccented forms and the British Pound Sterling symbol with the word pounds. \n",
    "\n",
    "The novel is divided into four books, each based in different regions of the world. You can start with the second book, which is titled *BOOK II.\\-\\-MACQUARIE HARBOUR.  1833*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on |  FtToHNL_BOOK_2.txt\n"
     ]
    }
   ],
   "source": [
    "#filename=\"FtToHNL_BOOK_1.txt\"\n",
    "filename=\"FtToHNL_BOOK_2.txt\"\n",
    "print(\"Working on | \", filename)\n",
    "\n",
    "# set the specific path for the 'filename' which is basically working through a list of everything that is in the folder\n",
    "textlocation = os.path.normpath(os.path.join(text_directory, filename))\n",
    "text_filename = os.path.basename(textlocation)\n",
    "\n",
    "text = open(textlocation, encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no more than a long string of characters. So far, you have done no processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:499] # look at the first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition <a class=\"anchor\" id=\"section-ner\"></a>\n",
    "*This section provides tools on identifying named entities in textual data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for NEs <a class=\"anchor\" id=\"section-nes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entities (NEs) are proper noun phrases within text, like names of places, people or organisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various packages that can include Named Enity Recognition (NER), e.g., the [Stanza CoreNLP](https://colab.research.google.com/github/stanfordnlp/stanza/blob/main/demo/Stanza_CoreNLP_Interface.ipynb), the Stanford NER, and the spaCy library. They often combine machine learning and a rule-based system to identify NEs and classify them into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, you will be using the spaCy NER - https://spacy.io/usage/linguistic-features#morphology .  This is available as a Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy allows you to load a language model that has been trained on various examples of the language of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy will automatically run the model through various levels of natural language processing. This pipeline includes tokenising the text into individual tokens or terms, like words, values and puncuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update\n",
    "\n",
    "It is simple to use the client. You just tell it to annotate the text. However, Stanza allows you to specify what to annotate the text with. For instance, you might want it to tokenise the terms, label their parts-of-speech and lemmatised forms as well as recognising any NEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The options for the Stanza client include:<ul>\n",
    "    <li> <strong>tokenize - </strong> split into words or terms </li> \n",
    "      <li>    <strong>ssplit - </strong> split into sentences or independent statements</li> \n",
    "     <li>     <strong>pos -  </strong> syntactic parts-of-speech</li> \n",
    "      <li>    <strong>lemma -  </strong> lemmatised form (not always a root form)</li> \n",
    "      <li>    <strong>ner - </strong> named entity recognition</li> \n",
    "      <li>    <strong>depparse -  </strong> parsing of dependencies</li> \n",
    "      <li>    <strong>coref - </strong> co-reference resolution</li> \n",
    "      <li>    <strong>kbppandas - </strong> KBP competition format</li> \n",
    "</ul>\n",
    "A full explanation can be found at <a href=\"https://stanfordnlp.github.io/CoreNLP/pipeline.html\">https://stanfordnlp.github.io/CoreNLP/pipeline.html</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the default line contains the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text sent to the spaCy model will be processed by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample text\n",
    "sampletext = \"Autonomous cars shift insurance liability toward manufacturers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sampletext)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the pipeline is then  available in the output structure of the spaCy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text,\" - \", \"Morph: \",token.morph, \n",
    "          \"\\n   Dep: \",token.dep_, \n",
    "          \"\\n   Head: \",token.head.text, \n",
    "          \"\\n   Pos: \",token.head.pos_,\n",
    "          \"\\n   Child: \",[child for child in token.children])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you might not want some of this pipeline processing as it may not be beneficial to your analysis. Any unneeded processing will also slow the system down and place a greater demand on the memory. This is particularly true of the parser. Luckily, it is easy to stipulate what you want excluded from the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(sampletext, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text,\" - \", \"Morph: \",token.morph, \n",
    "          \"\\n   Dep: \",token.dep_, \n",
    "          \"\\n   Head: \",token.head.text, \n",
    "          \"\\n   Pos: \",token.head.pos_,\n",
    "          \"\\n   Child: \",[child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, what you are interested in is the NER. Each sentence sent down the pipeline with the ner will get a list of entities that have been found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletext = \"Apple is looking at buying a U.K. startup based in London for $1 billion.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sampletext)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"[\",ent.label_,\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each entity is labelled with a category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: UPDATE\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    The NER categories classified by Stanza include:\n",
    "   <ul>\n",
    "<li><strong>Default:</strong>\n",
    "LOCATION, ORGANIZATION, PERSON</li>\n",
    "<li><strong>High recall: </strong>\n",
    "DATE, LOCATION, MONEY, ORGANIZATION, PERCENT, PERSON, TIME, MISC</li>\n",
    "<li><strong>KBP fine-grained:</strong>\n",
    "CAUSE_OF_DEATH, CITY, COUNTRY, CRIMINAL_CHARGE, EMAIL, HANDLE,\n",
    "IDEOLOGY, NATIONALITY, RELIGION, STATE_OR_PROVINCE, TITLE, URL</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update\n",
    "\n",
    "Most tokenised terms in the sentence have O as their NER value (that is the letter O not the number 0). Some however have been categorised. For instance, Van and Diemen are both classified as being PERSON named entities, Tasman is an ORGANIZATION and Cape and Pillar are in the LOCATION category. These categories are specific to Stanza. There are two key levels of processing available - the normal level will only identify the categories LOCATION, ORGANIZATION and PERSON, but the high recall processing will also consider other specialised phrases like TIME and MONEY which are not really named entities. Stanza can also look for the categories used in the KBP competition like CITY, COUNTRY and NATIONALITY, but this fine-grained processing will be slower.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the entities includes the character position for the start and the end of the NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sampletext)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each token will also have a value that indicates whether it is part of an NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"[\", token.ent_type_, \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update\n",
    "\n",
    "The annotations so far show that *Cape* and *Pillar* are both a LOCATION NE, but not that *Cape Pillar* is actually the complete name of the location. However Stanza does also recognise multi-word expressions (MWEs), even though it recognises that they are part of an NE. Each *Sentence* annotated by Stanza has a list of [NE *Mentions*](https://stanfordnlp.github.io/CoreNLP/entitymentions.html) which are also given NER categories as their *Type*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to hand-code entities after the NER has been done. This can help make up for any common irregularities with the NER for your input documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, this model doesn't recognise that FB is a NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletext = \"FB is hiring a new vice president of global policy\"\n",
    "\n",
    "doc = nlp(sampletext)\n",
    "ents = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "print('Entities before:', ents)\n",
    "# The model didn't recognize \"fb\" as an entity :-("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to create a new entry for the list of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spaCy span for the new entity\n",
    "fb_ent = Span(doc, 0, 1, label=\"ORG\")\n",
    "orig_ents = list(doc.ents)\n",
    "\n",
    "# Assign a complete list of ents to doc.ents\n",
    "doc.ents = orig_ents + [fb_ent]\n",
    "\n",
    "ents = [(ent.text, ent.start, ent.end, ent.label_) for ent in doc.ents]\n",
    "print('Entities after:', ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the data for the tokens is updated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"[\", token.ent_type_, \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy also allows the input documents to be processed in batches. This helps better manage the processing demands of the system throughout the pipeline when there are multiple files or many sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple texts in a list\n",
    "sampletexts = [\"Autonomous cars shift insurance liability toward manufacturers\",\"This is a text\", \"These are lots of texts\", \"...\"]\n",
    "\n",
    "# remove what elements you don't need from the pipeline\n",
    "for doc in nlp.pipe(sampletexts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    print(\"Entities: \",[(ent.text, ent.label_) for ent in doc.ents])\n",
    "    for token in doc:\n",
    "        print(\"   \",token.text, \"[\", token.ent_type_, \"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can process the output of the piped pipeline straight away, you can't print it unless you convert it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(sampletexts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Can't remember what this is trying to do. Think it has to do with the IOB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.attrs import ENT_IOB, ENT_TYPE\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#doc = nlp.make_doc(\"London is a big city in the United Kingdom and New York is in the United States of America.\")\n",
    "doc = nlp(\"London is a big city in the United Kingdom and New York is in the United States of America.\")\n",
    "\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(\"Entities: \",ents)\n",
    "\n",
    "print(\"\\nBefore:\", doc.ents)  # []\n",
    "\n",
    "header = [ENT_IOB, ENT_TYPE]\n",
    "attr_array = np.zeros((len(doc), len(header)), dtype=\"uint64\")\n",
    "attr_array[0, 0] = 3  # B\n",
    "attr_array[0, 1] = doc.vocab.strings[\"GPE\"]\n",
    "doc.from_array(header, attr_array)\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(\"\\nEntities: \",ents)\n",
    "\n",
    "print(\"\\nAfter\", doc.ents)  # [London]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Placeholder in-case we want to show of the displacy rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletext = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sampletext)\n",
    "\n",
    "# displacy from spaCy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: talk about extracting just the NER types we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain('LOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain('FAC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain('ORG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Run through a single chapter (variable: text) before doing the entire collection?\n",
    "    This will allow all NEs to be shown, then the filter be introduced.\n",
    "    This will put it more on topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "# document level\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    \n",
    "i=0 # entity counter\n",
    "# token level\n",
    "for e in doc.ents:\n",
    "    print(\"{:5}\\t\\t{:30s}\\t{}\".format(i+1,e.text, e.label_))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Expand on this explanation with example context.\n",
    "Talk about the issue with _Van Diemen's_ versus _Van Diemen's Land_ (and _Tasman's Head_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These categories are assigned according to the context in which the NE is used. For this reason, _Van Diemen's_ is considered an *ORG*, a *PERSON* and a *FAC*, depending on its linguistic context. Note also that _VAN DIEMEN'S LAND_ in the title of the chapter isn't recognised as a NE, probably due to its unconventional case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Expand on this explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, not all of these NE are suitable for placenames, so you will need to make a list of what categories regularly contain placenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACENAME_CATEGORIES = [\"LOC\", \"GPE\", \"FAC\", \"ORG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing Candidate Placenames <a class=\"anchor\" id=\"section-reviewplacenames\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now put all of this together and find the placenames that are identified by spaCy in each chapter of the text. They can all be collected in a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we store the details about each instance of the placenames\n",
    "placenames_df = pd.DataFrame(columns=['Book','Chapter',\"NEIndex\",\"Placename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which chapters and books you want to annotate\n",
    "CHAPTERS=[1,2,3] \n",
    "BOOKS=[1,2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You should define what spaCy processing you do or don't want in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disabledPipeline=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's process FtToHNL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "i=0 # counter of the entities\n",
    "for b in BOOKS:\n",
    "    for c in CHAPTERS:\n",
    "        filename = \"FtToHNL_BOOK_\"+str(b)+\"_CHAPTER_\"+str(c)+\".txt\" \n",
    "        # set the specific path for the 'filename'\n",
    "        textlocation = os.path.normpath(os.path.join(text_directory, filename))\n",
    "        text_filename = os.path.basename(textlocation)\n",
    "\n",
    "        # read this chapter\n",
    "        text = open(textlocation, encoding=\"utf-8\").read()\n",
    "        print(\"Working on |\",filename)\n",
    "        \n",
    "        # run spaCy    \n",
    "        doc = nlp(text,disable=disabledPipeline)\n",
    "\n",
    "        # document level\n",
    "        ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "\n",
    "        # token level\n",
    "        for e in doc.ents:\n",
    "            if e.label_ in PLACENAME_CATEGORIES: # filter out MONEY, DATE etc\n",
    "                print(\"{:5}\\t\\t{:30s}\\t{}\".format(i+1,e.text, e.label_))\n",
    "                # To help understand the context of the text, extract the occurence\n",
    "                context_text=doc.text[e.start_char-30:e.end_char+30].replace(\"\\n\",\" \")\n",
    "                \n",
    "                # Code to render with displacy\n",
    "                #context_doc={\"text\":str(i+1)+\" \\t \"+context_text,\n",
    "                #             \"ents\":[{\"start\": len(str(i+1)+\"   \")+30, \n",
    "                #                      \"end\":   len(str(i+1)+\"   \"+context_text)-30, \n",
    "                #                      \"label\": e.label_}],\n",
    "                #             \"title\": None}\n",
    "                #print(context_doc)\n",
    "                #displacy.render(context_doc, style=\"ent\", manual=True, jupyter=True)\n",
    "\n",
    "                # find the placenames according to spaCy\n",
    "                new_placename = {'Book':b,              # The Book number\n",
    "                                'Chapter':c,            # The Chapter number\n",
    "                                'NEIndex':i,            # A reference number to the nth Named Entity \n",
    "                                'Placename':e.text,     # The placename in the text\n",
    "                                'Category':e.label_,    # The spaCy category\n",
    "                                'Context':context_text, # The textual context where the placename was found\n",
    "                                'Approval':1}        # A flag for whether this is a suitable placename\n",
    "                placenames_df = placenames_df.append(new_placename, ignore_index=True)\n",
    "                \n",
    "            i=i+1 # entity counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placenames_df[['Book','Chapter','NEIndex','Placename','Category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that a lot more placenames were found in Book 2 than Book 1. This makes sense since Book 1 is set on board an ocean voyage, whereas Book 2 is at Macquarie Harbour in Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are a number of NEs that are unlikely to be placenames, regardless of what spaCy categoriesd them as. It is best to consider the context in which the terms were used. Use the checkboxes to select which terms you do consider to be placenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ipywidgets as widgets\n",
    "\n",
    "def changed(b):\n",
    "    # The system sets the _property_lock_, changes the value, then releases the _property_lock_.\n",
    "    # The confusing thing is that there is a value for the checkbox and a value for the property lock.\n",
    "    # changed() is called three times for every change to the checkbox.\n",
    "\n",
    "    # If you want to see any change to the checkbox value, uncomment this print()) command\n",
    "    if b['name']=='value':\n",
    "        #print(b,\"\\n\")\n",
    "        #print(\"found value\")\n",
    "        k=b['new']\n",
    "        #print(\"    \",k)\n",
    "    #print(b,\"\\n\")\n",
    "\n",
    "placename_items=[]\n",
    "context_items=[]\n",
    "num_items=[]\n",
    "\n",
    "# Time to try to make checkboxes for every placename for b in BOOKS:\n",
    "for b in BOOKS:\n",
    "    for c in CHAPTERS:\n",
    "        # Get the NEs from this book and chapter\n",
    "        pbc=placenames_df[(placenames_df[\"Book\"]==b) & (placenames_df[\"Chapter\"]==c)]\n",
    "        for i in pbc[\"NEIndex\"]:\n",
    "            context_text=pbc[pbc[\"NEIndex\"]==i][\"Context\"].values[0]\n",
    "            category=pbc[pbc[\"NEIndex\"]==i][\"Category\"].values[0]\n",
    "            \n",
    "        # Make lists of the candidate placenames, context text and index numbers \n",
    "        # Only the placenames are given a checkbox. \n",
    "        placename_items = placename_items + [widgets.Checkbox(True,description=i) for i in pbc[\"Placename\"]]\n",
    "        context_items = context_items + [widgets.Label(pbc[pbc[\"NEIndex\"]==i][\"Context\"].values[0]) for i in pbc[\"NEIndex\"]]\n",
    "        num_items = num_items + [widgets.Label(str(i)) for i in pbc[\"NEIndex\"]]\n",
    "\n",
    "# create a display\n",
    "num_placenames=len(placename_items)\n",
    "left_box = widgets.VBox(placename_items)\n",
    "right_box = widgets.VBox(context_items)\n",
    "num_box = widgets.VBox(num_items)\n",
    "whole_box = widgets.HBox([num_box, left_box, right_box])\n",
    "        \n",
    "display(whole_box)\n",
    "\n",
    "# respond to any changes in the checkboxes\n",
    "for i in range(num_placenames):\n",
    "    placename_items[i].observe(changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now copy all the values from the checkboxes to the data, so you know which placenames you have approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the status of each checklist item to the data\n",
    "for i in range(num_placenames):\n",
    "    #print(num_items[i].value,placename_items[i].value,placename_items[i].description)\n",
    "\n",
    "    NEIndex_num = int(num_items[i].value)\n",
    "    approval_flag = placename_items[i].value\n",
    "    \n",
    "    #print(\"Looking for [\"+str(NEIndex_num)+\"]\")\n",
    "    \n",
    "    # set the flag to match the checklist\n",
    "    for p in placenames_df[\"NEIndex\"]:\n",
    "        if (p-NEIndex_num == 0):\n",
    "            placenames_df.loc[placenames_df[\"NEIndex\"] == NEIndex_num,\"Approval\"] = approval_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now visualise the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placenames_df[['NEIndex','Placename','Approval']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, you can extract the final list of distinct placenames that you have approved. While the names aren't sorted (though they could be), if you missed unselecting an NE on the checklist, this will help find it. All you need to do is go back to the checklist, unselect it, then run all other steps from there to here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a unique list of the approved placenames\n",
    "approved_placenames = placenames_df[placenames_df[\"Approval\"]==True]['Placename'].unique()\n",
    "approved_placenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to save this new data to a csv file. You have already defined the directory for your data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"FtToHNL_placenames.csv\"\n",
    "save_location = os.path.normpath(os.path.join(csv_directory, filename))\n",
    "save_filename = os.path.basename(save_location)\n",
    "print(\"Saving to placename data to \",save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the list \n",
    "# using the savetxt from the numpy module\n",
    "np.savetxt(save_location, \n",
    "           approved_placenames,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Remove the MWE section as it is not needed for spaCy.\n",
    "Stopped the code form executing for now, but kept for reference while updating the above steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWEs as Named Entities  <a class=\"anchor\" id=\"section-mwes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotations so far show that *Cape* and *Pillar* are both a LOCATION NE, but not that *Cape Pillar* is actually the complete name of the location. However Stanza does also recognise multi-word expressions (MWEs), even though it recognises that they are part of an NE. Each *Sentence* annotated by Stanza has a list of [NE *Mentions*](https://stanfordnlp.github.io/CoreNLP/entitymentions.html) which are also given NER categories as their *Type*. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    print(\"{}\\t{:30s}\\t{}\".format(\"Sentence\", \"Mention\", \"Type\"))\n",
    "    for i, sent in enumerate(document.sentence):\n",
    "        for m in sent.mentions:\n",
    "            print(\"{:5}\\t\\t{:30s}\\t{}\".format(i+1,m.entityMentionText, m.entityType))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, this isn't perfect. While *Van Diemen* is recognised as a *PERSON* NE, *Van Diemen's Land* (i.e., the former name for Tasmania) isn't recognised as a *LOCATION*. This is because Stanza is trained to only recognise certain combinations of words and categories as a new MWE category. These rules can however be added to but this workshop won't explore this aspect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each token is also annotated with an index number corresponding to any Mention it is part of. Each token can only be part of one Mention. While the Mentions may be annotated per Sentence, the index number is actually considering all Sentences and Mentions in the annotated text."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TotalNumMentions=0 # keep a running list of how many NEs are identified\n",
    "print(\"{:15s}\\t{:15s}\\t{:6s}\\t{:10s}\\t{:10s}\\t{}\".format(\"word\",\"lemma\",\"POS\",\"NER\",\"Mention Index\",\"Mention\"))\n",
    "\n",
    "for i, sent in enumerate(document.sentence):\n",
    "    NumMentions = len(sent.mentions) # count how many NEs annotated to this sentence\n",
    "    if NumMentions:\n",
    "        print(\"\\n[Sentence {}]\".format(i+1))\n",
    "        for t in sent.token:\n",
    "            # only output tokens that are in NEs\n",
    "            if t.ner != 'O': # Letter, not zero!\n",
    "                # get the full text for the NE\n",
    "                mentionStr=sent.mentions[t.entityMentionIndex -  TotalNumMentions].entityMentionText                \n",
    "                print(\"{:15s}\\t{:15s}\\t{:6s}\\t{:10s}\\t{:10}\\t{}\".format(t.word, \n",
    "                                                                 t.lemma, \n",
    "                                                                 t.pos, \n",
    "                                                                 t.ner, \n",
    "                                                                 t.entityMentionIndex, \n",
    "                                                                 mentionStr))\n",
    "    TotalNumMentions += NumMentions # add to the running total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you are mainly interested in the Named Entities relate to locations. The location-based NER categories used by Stanza are:\n",
    "* *LOCATION*\n",
    "* *CITY*\n",
    "* *COUNTRY*\n",
    "* *STATE_OR_PROVINCE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NATIONALITY* might also be considered but it may depend on whether you care about phrases like *student of English history* or *Frenchman's cap*, or not.\n",
    "It is easy to filter out all other NEs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NATIONALITY is ignored \n",
    "LOCATION_CATEGORIES = ['LOCATION','CITY','COUNTRY','STATE_OR_PROVINCE']\n",
    "\n",
    "# Iterate over all detected entity mentions\n",
    "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\n",
    "\n",
    "STANZA_Locations = [] # list of locations Stanza recognises\n",
    "for sent in document.sentence:\n",
    "    for m in sent.mentions:\n",
    "        if (m.entityType in LOCATION_CATEGORIES): # ignore any nonLocation NEs\n",
    "            print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))\n",
    "            STANZA_Locations.append(m.entityMentionText)\n",
    "            \n",
    "print(\"\\n{}\".format(STANZA_Locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now put all of this together and find the placenames that are identified by Stanza in each chapter of the text. They can all be collected in a single dataframe."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "placenames = pd.DataFrame(columns=['Book','Chapter',\"NEIndex\",\"Placename\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# define which chapters and books you want to annotate\n",
    "CHAPTERS=[1,2,3] \n",
    "BOOKS=[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\\[MN Note\\]__ Change this to a background server, rather than a server on demand?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for b in BOOKS:\n",
    "    for c in CHAPTERS:\n",
    "        filename = \"FtToHNL_BOOK_\"+str(b)+\"_CHAPTER_\"+str(c)+\".txt\" \n",
    "        # set the specific path for the 'filename' which is basically working through a list of everything that is in the folder\n",
    "        textlocation = os.path.normpath(os.path.join(text_directory, filename))\n",
    "        text_filename = os.path.basename(textlocation)\n",
    "\n",
    "        # read this chapter\n",
    "        text = open(textlocation, encoding=\"utf-8\").read()\n",
    "        print(\"Working on |\",filename)\n",
    "        \n",
    "        # run the Stanza server & client\n",
    "        # https://nlp.stanford.edu/software/regexner.html\n",
    "        # java -mx1g -cp '*' edu.stanford.nlp.pipeline.StanfordCoreNLP \n",
    "        #      -annotators 'tokenize,ssplit,pos,lemma,ner' -file JuliaGillard.txt\n",
    "        # java -mx1g -cp '*' edu.stanford.nlp.pipeline.StanfordCoreNLP \n",
    "        #      -annotators 'tokenize,ssplit,pos,lemma,ner,regexner' -file JuliaGillard.txt\n",
    "        #      -regexner.mapping jg-regexner.txt\n",
    "        #\n",
    "        # with CoreNLPClient(properties={\n",
    "        #  'annotators': 'tokenize,ssplit,pos',\n",
    "        #  'pos.model': '/path/to/custom-model.ser.gz'\n",
    "        # }) as client:\n",
    "        #with CoreNLPClient(annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner','regexner'], \n",
    "        #           memory='4G', \n",
    "        #           annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner','regexner'], \n",
    "        #           endpoint='http://localhost:9001', \n",
    "        #           be_quiet=True) as client:\n",
    "        with CoreNLPClient(properties={\n",
    "            'annotators': 'tokenize,ssplit,pos,lemma,ner,regexner', \n",
    "            'regexner.mapping':'jg-regexner.txt',\n",
    "            'memory':'4G', \n",
    "            'endpoint':'http://localhost:9001', \n",
    "            'be_quiet':True\n",
    "        }) as client:\n",
    "            # Annotate the text (presuming it is not too large)\n",
    "            document = client.annotate(text)\n",
    "        \n",
    "        # find the placenames according to Stanza\n",
    "        for sent in document.sentence:\n",
    "            for m in sent.mentions:\n",
    "                if (m.entityType in LOCATION_CATEGORIES):\n",
    "                    new_placename = {'Book':b,\n",
    "                                    'Chapter':c,\n",
    "                                    'NEIndex':m.entityMentionIndex,\n",
    "                                    'Placename':m.entityMentionText,\n",
    "                                    'Category':m.entityType}\n",
    "                    placenames = placenames.append(new_placename, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that a lot more placenames were found in Book 2 than Book 1. This makes sense since Book 1 is set on board an ocean voyage, whereas Book 2 is at Macquarie Harbour in Australia.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to save this new data to a csv file. You have already defined the directory for your data files."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filename = \"FtToHNL_placenames_v2.txt\"\n",
    "save_location = os.path.normpath(os.path.join(csv_directory, filename))\n",
    "save_filename = os.path.basename(save_location)\n",
    "print(\"Saving placename data to \",save_location)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "placenames.to_csv(save_location)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Locations for the Placenames <a class=\"anchor\" id=\"section-findinglocs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a list of placenames from the text, the next step is to work out their location on Earth. For this you can use a combination of specialised lists of locations, gazzetteers and heuristics. The objective is to match every placename with the coordinates of a known location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to read the file of your placenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on |  FtToHNL_placenames.csv\n"
     ]
    }
   ],
   "source": [
    "filename=\"FtToHNL_placenames.csv\"\n",
    "print(\"Working on | \", filename)\n",
    "\n",
    "# set the specific path for the 'filename' which is basically working through a list of everything that is in the folder\n",
    "data_location = os.path.normpath(os.path.join(csv_directory, filename))\n",
    "data_filename = os.path.basename(data_location)\n",
    "\n",
    "# Using pandas, read the csv file. This will place it in a dataframe format. \n",
    "placenames_df = pd.read_csv(data_location, encoding=\"utf-8\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "placenames_df = placenames_df.rename(columns={placenames_df.columns[0]: 'Placename'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Placename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the sleepy sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the Bay of Biscay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Van Diemen's Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Grummet Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Grummet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Malabar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Dawes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Placename\n",
       "0      the sleepy sea\n",
       "1   the Bay of Biscay\n",
       "2               Heath\n",
       "3              London\n",
       "4   Van Diemen's Land\n",
       "..                ...\n",
       "75     Grummet Island\n",
       "76            Grummet\n",
       "77            Malabar\n",
       "78              Dawes\n",
       "79             Sydney\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placenames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying States and Capitals <a class=\"anchor\" id=\"section-statescapitals\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some placenames, like *High Street* or *Maryborough*, may be very common across the world, or even in Australia. However, certain placenames refer to significant locations, like states, territories, large geographic features or capital cities. As such, if they are mentioned in a text, the placename is more likely to refer to the major location than a town or village in Tasmania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These significant locations are a finite set. They can be defined in a reference file that can be reused when reviewing the placenames of any text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good point for you to start is a file about locations like modern capital cities and countries, combined with historical locations of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on |  reference_location_data.csv\n"
     ]
    }
   ],
   "source": [
    "filename=\"reference_location_data.csv\"\n",
    "print(\"Working on | \", filename)\n",
    "\n",
    "# set the specific path for the 'filename' which is basically working through a list of everything that is in the folder\n",
    "reference_location = os.path.normpath(os.path.join(reference_directory, filename))\n",
    "reference_filename = os.path.basename(reference_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than reading this and then processing it, you can process each line as you read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the reference data in a dataframe\n",
    "locref_df = pd.read_csv(reference_location, encoding=\"utf-8\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>PartOf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuja</td>\n",
       "      <td>Capital</td>\n",
       "      <td>9.083333</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accra</td>\n",
       "      <td>Capital</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>-0.216667</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adamstown</td>\n",
       "      <td>Capital</td>\n",
       "      <td>-25.066667</td>\n",
       "      <td>-130.083333</td>\n",
       "      <td>Pitcairn Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>Capital</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aegina</td>\n",
       "      <td>Capital</td>\n",
       "      <td>37.740882</td>\n",
       "      <td>23.501421</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Zagreb</td>\n",
       "      <td>Capital</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Country</td>\n",
       "      <td>-15.416667</td>\n",
       "      <td>28.283333</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Zanzibar City</td>\n",
       "      <td>Capital</td>\n",
       "      <td>-6.165193</td>\n",
       "      <td>39.198914</td>\n",
       "      <td>Tanzania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Country</td>\n",
       "      <td>-17.816667</td>\n",
       "      <td>31.033333</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Zomba</td>\n",
       "      <td>Capital</td>\n",
       "      <td>-15.376586</td>\n",
       "      <td>35.335652</td>\n",
       "      <td>Malawi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LocationName Category  Longitude    Latitude            PartOf\n",
       "0            Abuja  Capital   9.083333    7.533333           Nigeria\n",
       "1            Accra  Capital   5.550000   -0.216667             Ghana\n",
       "2        Adamstown  Capital -25.066667 -130.083333  Pitcairn Islands\n",
       "3      Addis Ababa  Capital   9.033333   38.700000          Ethiopia\n",
       "4           Aegina  Capital  37.740882   23.501421            Greece\n",
       "..             ...      ...        ...         ...               ...\n",
       "543         Zagreb  Capital  45.800000   16.000000           Croatia\n",
       "544         Zambia  Country -15.416667   28.283333            Africa\n",
       "545  Zanzibar City  Capital  -6.165193   39.198914          Tanzania\n",
       "546       Zimbabwe  Country -17.816667   31.033333            Africa\n",
       "547          Zomba  Capital -15.376586   35.335652            Malawi\n",
       "\n",
       "[548 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locref_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[TODO\\]: update this text chunk to suit the workshop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if you are researching historical texts, then some of these contemporary locations may have had different names. Old New York was once New Amsterdam (and had the [nickname of Gotham](https://www.nypl.org/blog/2011/01/25/so-why-do-we-call-it-gotham-anyway), amongst others). Istanbul was Constantinople. Some locations had [romanized names](https://en.wikipedia.org/wiki/Chinese_postal_romanization), like Beijing being called Peking. They may be a long time gone but you might want to add them to the list of significant known locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another historical variant is changing which cities are the capitals. These may be due to political decisions, like the movement of the Australian parliament from Melbourne to the new city of Canberra, or they could be a necessity due to the results of war, like Bonn becoming the capital of West Germany after World War II. These older capitals may also have to be accomodated in your reference data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because FtToHNL is set in the 19th Century CE, the next step is to add various capital cities from then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also larger geopolitical regions that may have been associated with placenames and cultures, for instance empires, dynasties and colonies like the British Empire or the Zulu Kingdom. Again, the borders and applicability of these political entities changed over time, so a contemporary reference list may not include them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 19th Century CE was a time of many European Empires so for FtToHNL, you will need to add reference data associated with relevant entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When processing this reference file, you can add the old political entity, its capital (if known), the geographic region (like continent or part thereof) and the modern country it would be considered part of.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to see if any of the placenames from our selected chapters of FtToHNL match these locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TO DO] Describe this without being technical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we match a placename, copy the geolocation data for the matching location. Otherwise, keep it empty so we know to keep looking for the placename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still looking for  the sleepy sea\n",
      "Still looking for  the Bay of Biscay\n",
      "Still looking for  Heath\n",
      "*** Found London [Exact match]\n",
      "{'placename': 'London', 'locations': {'best_match':     LocationName Category  Longitude  Latitude          PartOf\n",
      "266       London  Capital       51.5 -0.083333  United Kingdom}}\n",
      "Still looking for  Van Diemen's Land\n",
      "Still looking for  Vickers\n",
      "Still looking for  Sylvia\n",
      "Still looking for  Bath\n",
      "Still looking for  Julia Vickers's\n",
      "Still looking for  Frere\n",
      "Still looking for  Chatham\n",
      "Still looking for  CHAPTER II\n",
      "Still looking for  Surgeon Pine\n",
      "Still looking for  Coromandel\n",
      "Still looking for  Pine\n",
      "*** Found India [Exact match]\n",
      "{'placename': 'India', 'locations': {'best_match':     LocationName Category  Longitude  Latitude PartOf\n",
      "206        India  Country       28.6      77.2   Asia}}\n",
      "Still looking for  the Hydaspes for Calcutta\n",
      "Still looking for  the poop guard\n",
      "Still looking for  MONOTONY\n",
      "Still looking for  Three'll\n",
      "Still looking for  Van Diemen's\n",
      "Still looking for  Tasman\n",
      "Still looking for  Cape Pillar\n",
      "Still looking for  Pirates' Bay\n",
      "Still looking for  east\n",
      "Still looking for  west\n",
      "Still looking for  the Isle of Wight\n",
      "Still looking for  the South-West Cape\n",
      "Still looking for  Swan Port\n",
      "Still looking for  Mediterranean\n",
      "Still looking for  Maria Island\n",
      "Still looking for  the Three Thumbs\n",
      "Still looking for  Peninsula\n",
      "Still looking for  Storm Bay\n",
      "Still looking for  Storing Island\n",
      "*** Found Italy [Exact match]\n",
      "{'placename': 'Italy', 'locations': {'best_match':     LocationName Category  Longitude   Latitude  PartOf\n",
      "215        Italy  Country       41.9  12.483333  Europe}}\n",
      "Still looking for  Sorrell\n",
      "Still looking for  Bruny Island\n",
      "Still looking for  Mount Royal\n",
      "Still looking for  D'Entrecasteaux Channel\n",
      "Still looking for  Actaeon\n",
      "Still looking for  the South Cape\n",
      "Still looking for  New Norfolk\n",
      "Still looking for  Derwent\n",
      "Still looking for  the Southern Ocean\n",
      "Still looking for  Tamar\n",
      "*** Found Victoria [Exact match]\n",
      "{'placename': 'Victoria', 'locations': {'best_match':     LocationName Category  Longitude  Latitude      PartOf\n",
      "523     Victoria  Capital  -4.616667     55.45  Seychelles}}\n",
      "Still looking for  Port Philip Bay\n",
      "*** Found Wellington [Exact match]\n",
      "{'placename': 'Wellington', 'locations': {'best_match':     LocationName Category  Longitude    Latitude       PartOf\n",
      "531   Wellington  Capital      -41.3  174.783333  New Zealand}}\n",
      "Still looking for  Dromedary\n",
      "Still looking for  Mount Wellington\n",
      "Still looking for  Launceston\n",
      "Still looking for  Smyrna\n",
      "Still looking for  Pyramid Island\n",
      "Still looking for  Rocky Point\n",
      "Still looking for  Port Davey\n",
      "Still looking for  Mount Direction\n",
      "Still looking for  Macquarie Harbour\n",
      "Still looking for  Mount Heemskirk\n",
      "Still looking for  Mount Zeehan\n",
      "Still looking for  King's River\n",
      "Still looking for  Sarah Island\n",
      "Still looking for  Philip's Island\n",
      "Still looking for  Hobart Town\n",
      "Still looking for  earth\n",
      "Still looking for  south-east\n",
      "Still looking for  Ladybird\n",
      "Still looking for  Commandant\n",
      "Still looking for  Port Arthur\n",
      "*** Found Honduras [Exact match]\n",
      "{'placename': 'Honduras', 'locations': {'best_match':     LocationName Category  Longitude   Latitude           PartOf\n",
      "200     Honduras  Country       14.1 -87.216667  Central America}}\n",
      "Still looking for  Arthur\n",
      "Still looking for  Hells Gates\n",
      "Still looking for  England\n",
      "Still looking for  New Town\n",
      "Still looking for  verandah.-She\n",
      "Still looking for  Grummet Island\n",
      "Still looking for  Grummet\n",
      "Still looking for  Malabar\n",
      "Still looking for  Dawes\n",
      "Still looking for  Sydney\n"
     ]
    }
   ],
   "source": [
    "\n",
    "geolocdata = [] # all the data about placenames and locations, once linked\n",
    "\n",
    "for placename in placenames_df['Placename']:\n",
    "    \n",
    "    # create a new geoloc entry about this placename\n",
    "    new_geolocdata={} \n",
    "    ## start a record for a placename\n",
    "    new_geolocdata['placename'] = placename\n",
    "    new_geolocdata['locations'] = {} # start with no location details\n",
    "    new_geolocdata['locations']['best_match'] = [] # start with no match\n",
    "    \n",
    "    # normalise its case and remove any leading whitespace\n",
    "    # This will be needed later for the gazzetteer\n",
    "    #safe_placename = urllib.parse.quote(placename.strip().lower()) \n",
    "\n",
    "    # Exact match\n",
    "    if(placename in list(locref_df['LocationName'])):\n",
    "        \n",
    "        print(\"*** Found\", placename,\"[Exact match]\")\n",
    "        # Copy the details from the reference file entry\n",
    "        new_geolocdata['locations']['best_match'] = locref_df[locref_df['LocationName']==placename]\n",
    "        \n",
    "    else:\n",
    "        print(\"Still looking for \", placename)\n",
    "    \n",
    "    # If you have a match, show it\n",
    "    if (len(new_geolocdata['locations']['best_match']) > 0):\n",
    "        print(new_geolocdata)\n",
    "        \n",
    "    geolocdata.append(new_geolocdata) # add the new placename data to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that you have recorded the matches (and mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'placename': 'the sleepy sea', 'locations': {'best_match': []}},\n",
       " {'placename': 'the Bay of Biscay', 'locations': {'best_match': []}},\n",
       " {'placename': 'Heath', 'locations': {'best_match': []}},\n",
       " {'placename': 'London',\n",
       "  'locations': {'best_match':     LocationName Category  Longitude  Latitude          PartOf\n",
       "   266       London  Capital       51.5 -0.083333  United Kingdom}},\n",
       " {'placename': \"Van Diemen's Land\", 'locations': {'best_match': []}},\n",
       " {'placename': 'Vickers', 'locations': {'best_match': []}},\n",
       " {'placename': 'Sylvia', 'locations': {'best_match': []}},\n",
       " {'placename': 'Bath', 'locations': {'best_match': []}},\n",
       " {'placename': \"Julia Vickers's\", 'locations': {'best_match': []}},\n",
       " {'placename': 'Frere', 'locations': {'best_match': []}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geolocdata[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What locations did you end up finding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London Capital 51.5 -0.083333 United Kingdom',\n",
       " 'India Country 28.6 77.2 Asia',\n",
       " 'Italy Country 41.9 12.483333 Europe',\n",
       " 'Victoria Capital -4.616667 55.45 Seychelles',\n",
       " 'Wellington Capital -41.3 174.783333 New Zealand',\n",
       " 'Honduras Country 14.1 -87.216667 Central America']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchdata = [p['locations']['best_match'].to_string(index=False,header=False) for p in geolocdata \n",
    "             if len(p['locations']['best_match'])>0]\n",
    "matchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching a Gazetteer for Locations <a class=\"anchor\" id=\"section-searchgazzeteer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search [Open Street Map (ODM)](https://nominatim.org/release-docs/develop/api/Search/) for locations that match the unknown placenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install ratelimit\n",
    "import requests\n",
    "from IPython.display import JSON\n",
    "import json\n",
    "from pprint import pprint\n",
    "from ratelimit import limits, RateLimitException, sleep_and_retry\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "placenames_small = [\"Brisbane\", \"Bruny Island\"]\n",
    "\n",
    "placenames_medium = [\"Bay of Marshmellows\", \"Bruny Island\", \"Derwent\"]\n",
    "\n",
    "placenames_large = [\"Actaeon reef\", \"Adriatic\", \"Australasian Continent\", \"Australian continent\", \"Bath\", \"Bay of Biscay\", \"Brighton\", \"Bruny Head\", \"Bruny Island\", \n",
    "                    \"Calcutta\", \"Cape Bougainville\", \"Cape Grim\", \"Cape Pillar\", \"Chatham ball-room\", \"Coromandel coast\", \n",
    "                    \"D'Entrecasteaux Channel\", \"Derwent\", \"Dromedary range\", \"England\", \"Grummet\", \"Grummet Island\", \n",
    "                    \"Halliday's Island\", \"Hell's Gates\", \"Hells Gates\", \"Hobart Town\", \"Hobart Town Gaol\", \"Hydaspes\", \"India\", \"Isle of Wight\", \"Italy\",\n",
    "                    \"Perth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many (max) results do we want for each name?\n",
    "#[TO DO] Make this a user setting, defaulting to 5\n",
    "# The normal is (Default: 10, Maximum: 50), according to https://nominatim.org/release-docs/develop/api/Search/\n",
    "limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send rate-limited requests that stay within n requests per second\n",
    "# [TO DO] add link to webpage about this\n",
    "@sleep_and_retry\n",
    "@limits(calls=1, period=1)\n",
    "def osm_call_api(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "# Format the api response to make comparison easier\n",
    "def osm_format_response(input):\n",
    "\n",
    "    # extract the country name, if any\n",
    "    hyperlocation = None;\n",
    "    if input[\"display_name\"].find(','):\n",
    "        # break up the address\n",
    "        namesplit = input[\"display_name\"].split(',')\n",
    "        # extract the rightmost term from the split\n",
    "        hyperlocation = namesplit[len(namesplit)-1]\n",
    "        #hyperlocation=len(namesplit)\n",
    "        \n",
    "        \n",
    "    # for now, keep the names the similiar to what OSM calls them\n",
    "    response = {\"Name\": input[\"display_name\"], \n",
    "              \"Type\": input[\"type\"],\n",
    "              \"Latitude\": input[\"lat\"], \n",
    "              \"Longitude\": input[\"lon\"],\n",
    "              \"PartOf\": hyperlocation,\n",
    "              \"Gazetteer\": \"OSM\",\n",
    "              \"Importance\": input[\"importance\"]\n",
    "                }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TO BE DONE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now move to the data that is needed for the geolocation project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for the sleepy sea\n",
      "looking for the Bay of Biscay\n",
      "  *   The Bay of Biscay, The Park, City of Nottingham, England, United Kingdom park 52.95425415 -1.159789836905746  United Kingdom OSM 0.55\n",
      "looking for Heath\n",
      "  *   Heath, Rockwall County, Texas, United States administrative 32.8365147 -96.474987  United States OSM 0.550181\n",
      "  *   Heath, Covington County, Alabama, United States administrative 31.3607243 -86.4696811  United States OSM 0.46\n",
      "  *   Heath, Licking County, Ohio, United States administrative 40.0228421 -82.4445991  United States OSM 0.459022\n",
      "  *   Heath, Franklin County, Massachusetts, United States administrative 42.6898311 -72.8178076  United States OSM 0.397419\n",
      "  *   Heath, Tippecanoe County, Indiana, 47924, United States hamlet 40.461147 -86.7333397  United States OSM 0.377719\n",
      "looking for Van Diemen's Land\n",
      "  *   Tasmania, Australia administrative -42.035067 146.6366887  Australia OSM 0.746767\n",
      "  *   Van Diemen's Land, Kempston Rural, Bedford, England, United Kingdom park 52.09974355 -0.5142026280666261  United Kingdom OSM 0.55\n",
      "looking for Vickers\n",
      "  *   Vickers, Northwood, Wood County, Ohio, 43619, United States hamlet 41.6117096 -83.4958794  United States OSM 0.36\n",
      "  *   Vickers, Hall County, Georgia, 30506, United States hamlet 34.3525983 -83.93685  United States OSM 0.36\n",
      "  *   Vickers, Kountze, Hardin County, Texas, 77625, United States residential 30.373898 -94.319196  United States OSM 0.21\n",
      "  *   Vickers, Stanton Fitzwarren, South Marston, Swindon, England, United Kingdom primary 51.59845985 -1.7415535311162076  United Kingdom OSM 0.21\n",
      "  *   Vickers, South Houston, Harris County, Texas, 77587, United States residential 29.6687304 -95.2244965  United States OSM 0.21\n",
      "looking for Sylvia\n",
      "  *   Sylvia, Reno County, Kansas, United States administrative 37.9580938 -98.4084398  United States OSM 0.526302\n",
      "  *   Sylvia, Dickson County, Tennessee, United States hamlet 36.1717246 -87.4255674  United States OSM 0.36\n",
      "  *   Sylvia, Pegg Addition, Batesville, Independence County, Arkansas, 72501, United States residential 35.7593667 -91.6302065  United States OSM 0.21\n",
      "  *   Sylvia, La Marque, Galveston County, Texas, 77568, United States residential 29.356695 -94.964718  United States OSM 0.21\n",
      "  *   Sylvia, Paliparan Subdivision, Santo NiÃ±o, Marikina, Eastern Manila District, Metro Manila, 1800, Pilipinas / Philippines residential 14.6413659 121.100725  Pilipinas / Philippines OSM 0.21\n",
      "looking for Bath\n",
      "  *   Bath, Bath and North East Somerset, West of England, England, United Kingdom city 51.3813864 -2.3596963  United Kingdom OSM 0.700632\n",
      "  *   Bath County, Kentucky, United States administrative 38.1245248 -83.7249243  United States OSM 0.608377\n",
      "  *   Bath, Sagadahoc County, Maine, 04530, United States administrative 43.910755 -69.820862  United States OSM 0.580224\n",
      "  *   Bath Abbey, Kingston Buildings, Kingsmead, Bath, Bath and North East Somerset, West of England, England, BA1 1LT, United Kingdom place_of_worship 51.3814544 -2.358865873946672  United Kingdom OSM 0.534873\n",
      "  *   Bath, Mason County, Illinois, United States administrative 40.1933784 -90.1409523  United States OSM 0.531862\n",
      "looking for Julia Vickers's\n",
      "looking for Frere\n",
      "  *   Ferrere, Asti, Piemonte, 14012, Italia administrative 44.875446 7.994732  Italia OSM 0.499995\n",
      "  *   Frere, Umtshezi Ward 8, Umtshezi Local Municipality, Uthukela District Municipality, KwaZulu-Natal, South Africa suburb -28.8922222 29.7747222  South Africa OSM 0.385\n",
      "  *   Frere, Acceglio, Cuneo, Piemonte, 12021, Italia hamlet 44.4701528 7.004274  Italia OSM 0.36\n",
      "  *   Frere, Clusone, Bergamo, Lombardia, 24023, Italia hamlet 45.879004 9.9476697  Italia OSM 0.36\n",
      "  *   Borgata Ferrere, Bernezzo, Cuneo, Piemonte, Italia hamlet 44.3666976 7.3916044  Italia OSM 0.25\n",
      "looking for Chatham\n",
      "  *   Chatham County, North Carolina, United States administrative 35.7151316 -79.2533035  United States OSM 0.626264\n",
      "  *   Chatham County, Georgia, United States administrative 31.9668887 -81.0626008  United States OSM 0.625755\n",
      "  *   Chatham, Medway, England, United Kingdom town 51.3819167 0.526559  United Kingdom OSM 0.59097\n",
      "  *   Chatham, Chatham-Kent, Southwestern Ontario, Ontario, N7M 2G6, Canada city 42.4057219 -82.1853837  Canada OSM 0.568228\n",
      "  *   Chatham, Sangamon County, Illinois, 62629, United States administrative 39.676163 -89.7045439  United States OSM 0.543383\n",
      "looking for CHAPTER II\n",
      "  *   Chapter II, Hemblington Road, Strumpshaw, Lingwood, Broadland, Norfolk, England, NR13 4NE, United Kingdom detached 52.6189908 1.4697835518955997  United Kingdom OSM 0.2001\n",
      "  *   Chapter II, Zahle - Dhor El Shweyr, Saydet En Najat, ØªÙ„ Ø´ÙŠØ­Ø§, Ø²Ø­Ù„Ø©, Ù‚Ø¶Ø§Ø¡ Ø²Ø­Ù„Ø©, Ù…Ø­Ø§ÙØ¸Ø© Ø§Ù„Ø¨Ù‚Ø§Ø¹, 1801, Ù„Ø¨Ù†Ø§Ù† bar 33.8546022 35.8947653  Ù„Ø¨Ù†Ø§Ù† OSM 0.2001\n",
      "  *   Chapter 2 Coffee Shop, Maes Derw, Llandudno Junction, Conwy, Cymru / Wales, LL31 9AL, United Kingdom cafe 53.284067199999996 -3.8021696863026877  United Kingdom OSM 0.1001\n",
      "looking for Surgeon Pine\n",
      "  *   Surgeon's Quarters, Flagstaff Hill Walkway, Kingston, Norfolk Island, Burnt Pine, Norfolk Island, 2899, Australia yes -29.057089050000002 167.95544200664628  Australia OSM 0.2001\n",
      "  *   Surgeon's Kitchen, Flagstaff Hill Walkway, Kingston, Norfolk Island, Burnt Pine, Norfolk Island, 2899, Australia yes -29.0569188 167.9554764  Australia OSM 0.2001\n",
      "looking for Coromandel\n",
      "  *   Coromandel, RegiÃ£o GeogrÃ¡fica Imediata de PatrocÃ­nio, RegiÃ£o GeogrÃ¡fica IntermediÃ¡ria de Patos de Minas, Minas Gerais, RegiÃ£o Sudeste, 38550-000, Brasil administrative -18.473889 -47.200278  Brasil OSM 0.519793\n",
      "  *   Coromandel, Thames-Coromandel District, Waikato, 3543, New Zealand / Aotearoa town -36.7571639 175.5007016  New Zealand / Aotearoa OSM 0.437161\n",
      "  *   Coromandel, Beau Bassin-Rose Hill, Plaines Wilhems, Outer islands of Mauritius, 71608, Mauritius suburb -20.1962831 57.4694395  Mauritius OSM 0.385\n",
      "  *   Coromandel, Johnson Parade, Blackwood, Adelaide, City of Mitcham, South Australia, 5051, Australia station -35.0251942 138.6143361  Australia OSM 0.317535\n",
      "  *   Coromandel, Caldecott, Abingdon on Thames, Abingdon, Vale of White Horse, Oxfordshire, England, OX14 5QQ, United Kingdom residential 51.6598155 -1.292693  United Kingdom OSM 0.21\n",
      "looking for Pine\n",
      "  *   Pine County, Minnesota, United States administrative 46.0820957 -92.7542126  United States OSM 0.619487\n",
      "  *   Pine, Tonto National Forest Exclusion Area, Arizona, 85544, United States administrative 34.3842741 -111.4555672  United States OSM 0.485002\n",
      "  *   Pinecrest Public School, 1281, McWatters Road, College, Ottawa, (Old) Ottawa, Ottawa, Eastern Ontario, Ontario, K2C 3E7, Canada school 45.3443641 -75.78478218194566  Canada OSM 0.380666\n",
      "  *   Pine, Gary, Lake County, Indiana, 46406, United States hamlet 41.6282297 -87.3944977  United States OSM 0.36\n",
      "  *   Pine, Camp County, Texas, United States hamlet 32.9131834 -94.9693811  United States OSM 0.36\n",
      "looking for the Hydaspes for Calcutta\n",
      "looking for the poop guard\n",
      "looking for MONOTONY\n",
      "looking for Three'll\n",
      "  *   Three, Waterville Valley, Grafton County, New Hampshire, United States cycleway 43.9445278 -71.4940105  United States OSM 0.285\n",
      "looking for Van Diemen's\n",
      "  *   Van Diemen Avenue, Summerhill, Launceston, City of Launceston, Tasmania, 7520, Australia residential -41.4654798 147.1314152  Australia OSM 0.4\n",
      "  *   Van Diemens Crescent, Park Grove, Burnie, City of Burnie, Tasmania, 7320, Australia residential -41.0585817 145.8838217  Australia OSM 0.4\n",
      "  *   Amsterdam-Van Diemenstraat, Van Diemenstraat, Zeeheldenbuurt, Amsterdam, Noord-Holland, Nederland, 1013 NH, Nederland monitoring_station 52.3899851 4.8878686  Nederland OSM 0.3001\n",
      "  *   Van Diemens Creamery, Christmas Hills Road, Elizabeth Town, Meander Valley, Tasmania, Australia ice_cream -41.4834771 146.5981326  Australia OSM 0.3001\n",
      "  *   Van Gogh Court, Newnham, Launceston, City of Launceston, Tasmania, 7248, Australia residential -41.3799529 147.1181359  Australia OSM 0.3\n",
      "looking for Tasman\n",
      "  *   Tasman, New Zealand / Aotearoa administrative -41.30222105 172.89453190955697  New Zealand / Aotearoa OSM 0.553039\n",
      "  *   Tasman, North 1st Street, San Jose, Santa Clara County, California, 95134, United States station 37.4086658 -121.9444674  United States OSM 0.434352\n",
      "  *   Tasman, Tasmania, Australia administrative -43.0422943 147.69664144273847  Australia OSM 0.427965\n",
      "  *   Tasman Bay / Te Tai-o-Aorere, Nelson, New Zealand / Aotearoa bay -41.0347888 173.34782222356634  New Zealand / Aotearoa OSM 0.421409\n",
      "  *   Tasman, New Zealand / Aotearoa village -41.1891054 173.0526542  New Zealand / Aotearoa OSM 0.385\n",
      "looking for Cape Pillar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *   Cape Pillar, Tasman, Tasmania, Australia administrative -43.1817045 147.9383047  Australia OSM 0.5\n",
      "  *   Cape Pillar, Tasman, Tasmania, Australia cape -43.2215036 148.0107165  Australia OSM 0.433229\n",
      "  *   Cape Pillar, Heard Island and McDonald Islands, Australia locality -53.1379539 73.4104006  Australia OSM 0.325\n",
      "looking for Pirates' Bay\n",
      "  *   Pirates Bay, Victoria, 3939, Australia bay -38.3792167 144.7708906  Australia OSM 0.4\n",
      "  *   Pirates Bay, Tasmania, 7179, Australia bay -43.021334 147.9384131  Australia OSM 0.4\n",
      "  *   pirates bay, Î‘Ï†Î¹ÏŽÎ½Î±Ï‚, Î ÎµÏÎ¹Ï†ÎµÏÎµÎ¹Î±ÎºÎ® Î•Î½ÏŒÏ„Î·Ï„Î± ÎšÎ­ÏÎºÏ…ÏÎ±Ï‚, Î ÎµÏÎ¹Ï†Î­ÏÎµÎ¹Î± Î™Î¿Î½Î¯Ï‰Î½ ÎÎ®ÏƒÏ‰Î½, Î‘Ï€Î¿ÎºÎµÎ½Ï„ÏÏ‰Î¼Î­Î½Î· Î”Î¹Î¿Î¯ÎºÎ·ÏƒÎ· Î ÎµÎ»Î¿Ï€Î¿Î½Î½Î®ÏƒÎ¿Ï…, Î”Ï…Ï„Î¹ÎºÎ®Ï‚ Î•Î»Î»Î¬Î´Î±Ï‚ ÎºÎ±Î¹ Î™Î¿Î½Î¯Î¿Ï…, 490 81, Î•Î»Î»Î¬Ï‚ bay 39.7149598 19.6571192  Î•Î»Î»Î¬Ï‚ OSM 0.4\n",
      "  *   Pirates Bay, Wirayudha, Nusa Dua, Benoa, Kuta Selatan, Bali, 80363, Indonesia restaurant -8.7998639 115.2354403  Indonesia OSM 0.2001\n",
      "  *   Pirates Bay, Ardi Beltza Path, Lombok Utara, Nusa Tenggara Barat, 83300, Indonesia travel_agency -8.3647299 116.0860116  Indonesia OSM 0.2001\n",
      "looking for east\n",
      "  *   Est, Burkina Faso state 12.2527495 0.8736106  Burkina Faso OSM 0.55\n",
      "  *   Est, Cameroun administrative 3.9894393 14.178373  Cameroun OSM 0.49897\n",
      "  *   Est, Burkina Faso administrative 12.255555 1.0095763618883151  Burkina Faso OSM 0.474977\n",
      "  *   East, Adjumani, Northern Region, Uganda village 3.4304084 31.7006378  Uganda OSM 0.375\n",
      "  *   Poblacion East, Candoni, Negros Occidental, Western Visayas, 6110, Pilipinas / Philippines quarter 9.8276999 122.6439348  Pilipinas / Philippines OSM 0.35\n",
      "looking for west\n",
      "  *   Western, West Kenya, Kenya state 0.5090396 34.5731341  Kenya OSM 0.65\n",
      "  *   Ouest, Cameroun state 5.5211184 10.6528684  Cameroun OSM 0.55\n",
      "  *   West, McLennan County, Texas, United States administrative 31.8034812 -97.0933471  United States OSM 0.542619\n",
      "  *   Western, Southern Region, Papua Niugini administrative -7.5 142  Papua Niugini OSM 0.524935\n",
      "  *   è¥¿ç¤West (London) Reef, Thá»‹ tráº¥n TrÆ°á»ng Sa, Huyá»‡n TrÆ°á»ng Sa, Tá»‰nh KhÃ¡nh HÃ²a, Viá»‡t Nam reef 8.861665949999999 112.1931736941656  Viá»‡t Nam OSM 0.488783\n",
      "looking for the Isle of Wight\n",
      "  *   Isle of Wight, England, United Kingdom island 50.67108245 -1.3328042802764226  United Kingdom OSM 0.890104\n",
      "  *   Isle of Wight, England, United Kingdom administrative 50.6710482 -1.3327111133199459  United Kingdom OSM 0.890104\n",
      "  *   Isle of Wight, England, United Kingdom fire 50.6710482 -1.3327111133199459  United Kingdom OSM 0.425\n",
      "  *   Isle of Wight, England, United Kingdom political 50.6710482 -1.3327111133199459  United Kingdom OSM 0.425\n",
      "  *   Isle of Wight, England, United Kingdom ceremonial 50.6710482 -1.3327111133199459  United Kingdom OSM 0.425\n",
      "looking for the South-West Cape\n",
      "  *   The Oaks Close, George South, George, George Local Municipality, Garden Route District Municipality, Western Cape, 6530, South Africa residential -33.9692821 22.4538144  South Africa OSM 0.5\n",
      "  *   The Mews Street, Glenhaven, Cape Town Ward 9, Bellville, City of Cape Town, Western Cape, 7580, South Africa residential -33.9185222 18.6551518  South Africa OSM 0.5\n",
      "  *   The Indraf Kafee, Cradock Street, George Ward 19, George, George Local Municipality, Garden Route District Municipality, Western Cape, 6530, South Africa convenience -33.9678234 22.456758  South Africa OSM 0.4001\n",
      "  *   The Best Of South Africa, Saint George's Street, Cape Town Ward 61, Simon's Town, City of Cape Town, Western Cape, 7995, South Africa yes -34.1929297 18.4288931  South Africa OSM 0.4001\n",
      "  *   MOSAIC Lagoon Cafe in the 1892 Spookhuis, Concrete Driveway, Overstrand Ward 3, Overstrand Local Municipality, Overberg District Municipality, Western Cape, 7210, South Africa cafe -34.4267527 19.3539093  South Africa OSM 0.4001\n",
      "looking for Swan Port\n",
      "  *   Swan, Intendance Street, Centre-Ville, Plaine Verte, Port Louis, Outer islands of Mauritius, 11317, Mauritius travel_agency -20.163587 57.5032798  Mauritius OSM 0.2101\n",
      "looking for Mediterranean\n",
      "  *   Mediterranean, Ä°skele, Kuzey KÄ±brÄ±s TÃ¼rk Cumhuriyeti, ÎšÏÏ€ÏÎ¿Ï‚ - KÄ±brÄ±s residential 35.255701349999995 33.904011953206904  ÎšÏÏ€ÏÎ¿Ï‚ - KÄ±brÄ±s OSM 0.31\n",
      "  *   Mediterranean, Palm Desert, Riverside County, California, 92210, United States residential 33.7439509 -116.3534839  United States OSM 0.21\n",
      "  *   Mediterranean, Marbella, Leander, Williamson County, Texas, United States residential 30.5742005 -97.8235544  United States OSM 0.21\n",
      "  *   Mediterranean, Newport, Crosby, Harris County, Texas, 77532, United States residential 29.918687 -95.0748985  United States OSM 0.21\n",
      "  *   Mediterranean, Wildwood, Cape May County, New Jersey, 08260, United States residential 38.9919995 -74.8279859  United States OSM 0.21\n",
      "looking for Maria Island\n",
      "  *   Maria Island, Glamorgan-Spring Bay, Tasmania, Australia island -42.655839799999995 148.10102607816566  Australia OSM 0.607433\n",
      "  *   Maria Island, Newfoundland, Newfoundland and Labrador, Canada island 51.230872149999996 -55.91464496489806  Canada OSM 0.525\n",
      "  *   Maria Island, Glamorgan-Spring Bay, Tasmania, Australia administrative -42.6358214 148.0849313  Australia OSM 0.5\n",
      "  *   Maria Island, Area A (Ocean Falls/Outer Coast), Central Coast Regional District, British Columbia, Canada islet 52.16230075 -127.92088142973815  Canada OSM 0.45\n",
      "  *   Maria Island, Carnaza, Cebu, Central Visayas, Pilipinas / Philippines islet 11.4927225 124.110195998596  Pilipinas / Philippines OSM 0.45\n",
      "looking for the Three Thumbs\n",
      "looking for Peninsula\n",
      "  *   Peninsula, Summit County, Ohio, United States administrative 41.241167 -81.552618  United States OSM 0.415004\n",
      "  *   Peninsula, Georgetown, Scott County, Kentucky, United States neighbourhood 38.221989199999996 -84.56188590725293  United States OSM 0.36\n",
      "  *   Peninsula, Georgetown, Scott County, Kentucky, United States administrative 38.221989199999996 -84.56188590725293  United States OSM 0.36\n",
      "  *   Peninsula, Daule, Guayas, 091902, Ecuador hamlet -1.8281384 -79.9893534  Ecuador OSM 0.36\n",
      "  *   Peninsula, Canton Victoria, Municipio Puerto Rico, Provincia de Manuripi, Pando, Bolivia hamlet -11.0856935 -67.3161825  Bolivia OSM 0.36\n",
      "looking for Storm Bay\n",
      "  *   Storm Bay, Tasmania, Australia bay -43.17 147.55569  Australia OSM 0.535162\n",
      "  *   Storm Bay, Unorganized Kenora District, Kenora District, Northwestern Ontario, Ontario, Canada bay 49.6780658 -94.3186347  Canada OSM 0.4\n",
      "  *   Storm Bay, Area B (Halfmoon Bay), Sunshine Coast Regional District, British Columbia, Canada bay 49.66505075 -123.82468428626042  Canada OSM 0.4\n",
      "  *   Storm Bay, New South Wales, 2533, Australia bay -34.6763083 150.8563045  Australia OSM 0.4\n",
      "  *   Storm Bay, Leeuwin, Shire Of Augusta Margaret River, Western Australia, Australia beach -34.34710185 115.1684147995006  Australia OSM 0.4\n",
      "looking for Storing Island\n",
      "looking for Sorrell\n",
      "  *   Sorrell, Caroline County, Virginia, United States hamlet 37.9543033 -77.1958098  United States OSM 0.41544\n",
      "  *   Sorrell, Sullivan County, Missouri, United States hamlet 40.2150201 -93.0204848  United States OSM 0.36\n",
      "  *   Sorrell, Red Oak, Ellis County, Texas, 75154, United States residential 32.5234174 -96.8170835  United States OSM 0.21\n",
      "  *   Sorrell, Hubert, Onslow County, North Carolina, 28539, United States residential 34.6957312 -77.2180922  United States OSM 0.21\n",
      "  *   Sorrell, Little Hallfield Road, The Groves, Layerthorpe, York, England, YO31 7XP, United Kingdom industrial 53.961450600000006 -1.0665293366389048  United Kingdom OSM 0.1101\n",
      "looking for Bruny Island\n",
      "  *   Bruny Island, Alonnah, Kingborough, Tasmania, Australia island -43.2898931 147.2890737745002  Australia OSM 0.600319\n",
      "looking for Mount Royal\n",
      "  *   Mount Royal, Lot 6, Prince County, Prince Edward Island, Canada administrative 46.6836433 -64.2583205  Canada OSM 0.55\n",
      "  *   Mont-Royal, MontrÃ©al, AgglomÃ©ration de MontrÃ©al, MontrÃ©al (06), QuÃ©bec, H3A 2B7, Canada peak 45.5086157 -73.5903112  Canada OSM 0.540034\n",
      "  *   Mont-Royal, AgglomÃ©ration de MontrÃ©al, MontrÃ©al (06), QuÃ©bec, Canada administrative 45.5143668 -73.6439247  Canada OSM 0.511213\n",
      "  *   Mount Royal, Anniston, Calhoun County, Alabama, 36207, United States peak 33.6634371 -85.791353  United States OSM 0.5\n",
      "  *   Mount Royal, Town of Conesville, Schoharie County, New York, United States peak 42.367304 -74.4251472  United States OSM 0.5\n",
      "looking for D'Entrecasteaux Channel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *   D'Entrecasteaux Channel, Middleton, Kingborough, Tasmania, 7150, Australia strait -43.23647525 147.3052940560143  Australia OSM 0.636225\n",
      "looking for Actaeon\n",
      "  *   Tweedelig hert, Mansholtlaan, Leeuwen, Wageningen, Gelderland, Nederland, 6708 PH, Nederland artwork 51.9864345 5.6694395  Nederland OSM 0.0001\n",
      "looking for the South Cape\n",
      "  *   Cape, Pipers Road, Park Farm South, Woodrow, Redditch, Worcestershire, England, B98 0HU, United Kingdom industrial 52.2840847 -1.9055396710979262  United Kingdom OSM 0.2101\n",
      "looking for New Norfolk\n",
      "  *   New Norfolk, Derwent Valley, Tasmania, Australia administrative -42.7801998 147.0615332  Australia OSM 0.489702\n",
      "  *   New Norfolk, Station Street, New Norfolk, Derwent Valley, Tasmania, Australia station -42.7760355 147.05581769761721  Australia OSM 0.2001\n",
      "looking for Derwent\n",
      "  *   Derwent, High Peak, Derbyshire, England, S33 0AX, United Kingdom administrative 53.39788105 -1.7078207528115286  United Kingdom OSM 0.473116\n",
      "  *   Derwent, Yorkshire Bridge, Bamford, High Peak, Derbyshire, England, S33 0BY, United Kingdom river 53.3674775 -1.7013735  United Kingdom OSM 0.385\n",
      "  *   Derwent, Hope Woodlands, High Peak, Derbyshire, England, S33 0BY, United Kingdom river 53.3645119 -1.7020654  United Kingdom OSM 0.385\n",
      "  *   Derwent, Guernsey County, Ohio, 43733, United States hamlet 39.9231278 -81.5442893  United States OSM 0.364365\n",
      "  *   Derwent, County of Two Hills, Alberta, Canada hamlet 53.6543655 -110.9657492  Canada OSM 0.36\n",
      "looking for the Southern Ocean\n",
      "  *   ocean, Î Î±Ï€Î±Î²Î±ÏƒÎ¹Î»ÎµÎ¯Î¿Ï…, ÎÎ¬Î¾Î¿Ï‚, Î”Î®Î¼Î¿Ï‚ ÎÎ¬Î¾Î¿Ï… ÎºÎ±Î¹ ÎœÎ¹ÎºÏÏŽÎ½ ÎšÏ…ÎºÎ»Î¬Î´Ï‰Î½, Î ÎµÏÎ¹Ï†ÎµÏÎµÎ¹Î±ÎºÎ® Î•Î½ÏŒÏ„Î·Ï„Î± ÎÎ¬Î¾Î¿Ï…, Î ÎµÏÎ¹Ï†Î­ÏÎµÎ¹Î± ÎÎ¿Ï„Î¯Î¿Ï… Î‘Î¹Î³Î±Î¯Î¿Ï…, Î‘Ï€Î¿ÎºÎµÎ½Ï„ÏÏ‰Î¼Î­Î½Î· Î”Î¹Î¿Î¯ÎºÎ·ÏƒÎ· Î‘Î¹Î³Î±Î¯Î¿Ï…, 843 00, Î•Î»Î»Î¬Ï‚ nightclub 37.1034349 25.3748431  Î•Î»Î»Î¬Ï‚ OSM 0.1001\n",
      "looking for Tamar\n",
      "  *   ØªØ¯Ù…Ø±, Ù†Ø§Ø­ÙŠØ© ØªØ¯Ù…Ø±, Ù…Ù†Ø·Ù‚Ø© ØªØ¯Ù…Ø±, Ù…Ø­Ø§ÙØ¸Ø© Ø­Ù…Øµ, Ø³ÙˆØ±ÙŠØ§ town 34.5560155 38.2809746  Ø³ÙˆØ±ÙŠØ§ OSM 0.53955\n",
      "  *   Tamar, Tolmin, 5243, Slovenija peak 46.2181038 13.9659246  Slovenija OSM 0.41\n",
      "  *   Tamar, Majhgawan Tahsil, Satna, Madhya Pradesh, India village 24.8828759 80.997167  India OSM 0.385\n",
      "  *   Tamar, Tamar I, Ranchi, Jharkhand, 835225, India village 23.0508104 85.65307  India OSM 0.385\n",
      "  *   Tamar, Maguindanao, Bangsamoro, Pilipinas / Philippines village 6.9639579 124.3362665  Pilipinas / Philippines OSM 0.385\n",
      "looking for Port Philip Bay\n",
      "  *   Yarra Bay Beach, Phillip Bay, Eastern Suburbs, Sydney, Randwick City Council, New South Wales, 2036, Australia beach -33.97894325 151.22918594272664  Australia OSM 0.3\n",
      "  *   Yarra Bay Bicentennial Park, Phillip Bay, Eastern Suburbs, Sydney, Randwick City Council, New South Wales, 2036, Australia park -33.977710200000004 151.22932069489116  Australia OSM 0.25\n",
      "looking for Dromedary\n",
      "  *   Dromedary, Central Highlands Regional, Queensland, Australia administrative -24.5859245 149.14648539120373  Australia OSM 0.41\n",
      "  *   Dromedary, New Zealand / Aotearoa peak -50.793525 166.0213152  New Zealand / Aotearoa OSM 0.41\n",
      "  *   Dromedary, Central Highlands Regional, Queensland, Australia locality -24.58722 149.12139  Australia OSM 0.235\n",
      "  *   Dromedary, Hobart, Brighton, Tasmania, 7030, Australia administrative -42.73886 147.16954  Australia OSM 0.15272\n",
      "  *   WielbÅ‚Ä…d jednogarbny, 1-5, Zygmunta WrÃ³blewskiego, Wittigowo, DÄ…bie, Osiedle Biskupin-SÄ™polno-DÄ…bie-Bartoszowice, WrocÅ‚aw, wojewÃ³dztwo dolnoÅ›lÄ…skie, 51-618, Polska attraction 51.1051282 17.0774613  Polska OSM 0.0001\n",
      "looking for Mount Wellington\n",
      "  *   kunanyi / Mount Wellington, City of Hobart, Tasmania, Australia peak -42.896007 147.2373052  Australia OSM 0.580634\n",
      "  *   Mount Wellington, Town of Springfield, Otsego County, New York, 13468, United States peak 42.8053512 -74.8732068  United States OSM 0.5\n",
      "  *   Mount Wellington, Area A (Egmont/Pender Harbour), Sunshine Coast Regional District, British Columbia, Canada peak 50.1389052 -123.9495681  Canada OSM 0.5\n",
      "  *   Mount Wellington, Clarence Valley Council, New South Wales, Australia peak -29.7009047 152.3844946  Australia OSM 0.5\n",
      "  *   Mount Wellington, Livingstone Shire, Queensland, Australia peak -22.6008333 149.8980556  Australia OSM 0.5\n",
      "looking for Launceston\n",
      "  *   Launceston, City of Launceston, Tasmania, 7250, Australia administrative -41.4340813 147.1373496  Australia OSM 0.624013\n",
      "  *   Launceston, City of Launceston, Tasmania, Australia administrative -41.4340813 147.1373496  Australia OSM 0.624013\n",
      "  *   Launceston, Cornwall, England, United Kingdom administrative 50.6365062 -4.3604432  United Kingdom OSM 0.618248\n",
      "  *   City of Launceston, Tasmania, Australia administrative -41.320994 147.27312884087405  Australia OSM 0.424671\n",
      "  *   Launceston, Tredydan Road, Launceston, Cornwall, England, PL15 8JA, United Kingdom station 50.6404065 -4.3648051  United Kingdom OSM 0.383082\n",
      "looking for Smyrna\n",
      "  *   Ä°zmir, Konak, Ä°zmir, Ege BÃ¶lgesi, 00000, TÃ¼rkiye city 38.4224548 27.1310699  TÃ¼rkiye OSM 0.622505\n",
      "  *   Smyrna, Kent County, Delaware, 19977, United States administrative 39.2998339 -75.6046494  United States OSM 0.555682\n",
      "  *   Smyrna, Cobb County, Georgia, United States administrative 33.883887 -84.5147454  United States OSM 0.535556\n",
      "  *   Smyrna, Rutherford County, Tennessee, 37167, United States town 35.9824598 -86.5199492  United States OSM 0.502487\n",
      "  *   Village of Smyrna, Town of Smyrna, Chenango County, New York, United States administrative 42.6872921 -75.5707376  United States OSM 0.492062\n",
      "looking for Pyramid Island\n",
      "  *   Pyramid Island, Haines, Alaska, United States islet 59.19742285 -135.4572064523979  United States OSM 0.45\n",
      "  *   Pyramid Island, Aleutians West Census Area, Alaska, United States islet 51.964949 178.31201332614398  United States OSM 0.45\n",
      "  *   Pyramid Island islet -62.417425699999995 -60.10306847698165 Pyramid Island OSM 0.45\n",
      "  *   Pyramid Island, Falkland Islands islet -52.002637750000005 -58.60553695423977  Falkland Islands OSM 0.45\n",
      "  *   Pyramid Island, Migori, Nyanza, Kenya island -0.90142105 33.93945448162722  Kenya OSM 0.400804\n",
      "looking for Rocky Point\n",
      "  *   Rocky Point, Town of Brookhaven, Suffolk County, New York, 11778, United States administrative 40.9525987 -72.9253805  United States OSM 0.607846\n",
      "  *   Rocky Point, Maricopa County, Arizona, United States hamlet 32.5336665 -112.8482119  United States OSM 0.569422\n",
      "  *   Rocky Point, Rural Municipality of Afton, Queens County, Prince Edward Island, Canada administrative 46.2024075 -63.1505008  Canada OSM 0.55\n",
      "  *   Rocky Point, Lake County, Montana, United States locality 47.731189 -114.18882405182927  United States OSM 0.511629\n",
      "  *   Rocky Point, Westfield, Hampden County, Massachusetts, United States peak 42.1153704 -72.853709  United States OSM 0.5\n",
      "looking for Port Davey\n",
      "  *   Port Davey, Huon Valley, Tasmania, Australia bay -43.2729083 145.94968056120592  Australia OSM 0.515064\n",
      "looking for Mount Direction\n",
      "  *   Mount Direction, Etheridge Shire, Queensland, Australia peak -17.9786111 143.8775  Australia OSM 0.5\n",
      "  *   Mount Direction, George Town, Tasmania, Australia administrative -41.24326 147.01687  Australia OSM 0.328161\n",
      "  *   Mount Direction, Shire of Pyrenees, Victoria, Australia peak -37.18681 143.33393  Australia OSM 0.26771\n",
      "  *   Mount Direction, George Town, Tasmania, Australia peak -41.24125 147.03311  Australia OSM 0.24272\n",
      "  *   Mount Direction, Hobart, City of Clarence, Tasmania, 7017, Australia peak -42.797977 147.3077395  Australia OSM 0.24272\n",
      "looking for Macquarie Harbour\n",
      "  *   Macquarie Harbour, Strahan, West Coast, Tasmania, Australia bay -42.33770255 145.403673139089  Australia OSM 0.549872\n",
      "looking for Mount Heemskirk\n",
      "  *   Mount Heemskirk, West Coast, Tasmania, Australia peak -41.85185 145.17221  Australia OSM 0.491903\n",
      "looking for Mount Zeehan\n",
      "  *   Mount Zeehan, Zeehan, West Coast, Tasmania, 7469, Australia peak -41.9267 145.3229  Australia OSM 0.2101\n",
      "looking for King's River\n",
      "  *   King's River, County Kilkenny, Leinster, R95 HE17, Ã‰ire / Ireland river 52.536908 -7.3401677  Ã‰ire / Ireland OSM 0.6\n",
      "  *   King's River, Mullinahone, The Municipal District of Carrick-on-Suir, County Tipperary, Munster, Ã‰ire / Ireland river 52.529434 -7.4677341  Ã‰ire / Ireland OSM 0.575\n",
      "  *   King's River, Modeshil, The Municipal District of Carrick-on-Suir, County Tipperary, Munster, Ã‰ire / Ireland river 52.5425973 -7.489768  Ã‰ire / Ireland OSM 0.575\n",
      "  *   King's River, Kells, The Municipal District of Callan â€” Thomastown, County Kilkenny, Leinster, R95 EFR9, Ã‰ire / Ireland river 52.5403557 -7.2580667  Ã‰ire / Ireland OSM 0.575\n",
      "  *   King's River, Callan Rural, The Municipal District of Callan â€” Thomastown, County Kilkenny, Leinster, R95 Y640, Ã‰ire / Ireland river 52.5345398 -7.3639866  Ã‰ire / Ireland OSM 0.575\n",
      "looking for Sarah Island\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *   Sarah Island, West Coast, Tasmania, Australia attraction -42.3895803 145.4473843  Australia OSM 0.536749\n",
      "  *   Sarah Island, Hingham, Plymouth County, Massachusetts, United States islet 42.25787595 -70.88530562994794  United States OSM 0.530718\n",
      "  *   á…á‘²á“•áŠá•á”ªá’ƒ Sarah Island, á•¿á‘­á–…á‘–á“—á’ƒ Qikiqtaaluk Region, á“„á“‡á•—á‘¦ Nunavut, Canada island 63.20785695 -64.54777755281438  Canada OSM 0.525\n",
      "  *   Sarah Island, Town of Bolton, Warren County, New York, United States islet 43.58316255 -73.57714508862614  United States OSM 0.45\n",
      "  *   Sarah Island, Unorganized Thunder Bay District, Thunder Bay District, Northwestern Ontario, Ontario, Canada islet 48.544094 -88.36470013398821  Canada OSM 0.45\n",
      "looking for Philip's Island\n",
      "  *   Saint Philip's Baptist Church, 77, Bennett Street, Port Richmond, Staten Island, City of New York, New York, 10302, United States place_of_worship 40.6377174 -74.13135692832495  United States OSM 0.3001\n",
      "  *   King Philip's Remains, Haile Street, Warren, Bristol County, Rhode Island, 02885, United States memorial 41.7229465 -71.2835099  United States OSM 0.3001\n",
      "  *   Philip Street, Wapping Wharf, Windmill Hill, Bristol, City of Bristol, West of England, England, BS3 4DR, United Kingdom unclassified 51.4427857 -2.5929537  United Kingdom OSM 0.3\n",
      "  *   St Philip's Road, Saint Vincent's, Philadelphia, Sheffield, South Yorkshire, Sheffield City Region, England, S3 7JZ, United Kingdom tertiary 53.3898938 -1.4798071  United Kingdom OSM 0.3\n",
      "  *   St. Philip's Lane, Saint Vincent's, Philadelphia, Sheffield, South Yorkshire, Sheffield City Region, England, S3 7JZ, United Kingdom residential 53.3895222 -1.4796846  United Kingdom OSM 0.3\n",
      "looking for Hobart Town\n",
      "  *   Village of Hobart, Town of Stamford, Delaware County, New York, United States administrative 42.3714704 -74.6704311  United States OSM 0.601151\n",
      "looking for earth\n",
      "  *   Earth, Lamb County, Texas, United States administrative 34.2331373 -102.4107493  United States OSM 0.533546\n",
      "  *   Earth, Calle Los Castillo, Dulce Nombre, RÃ­o JimÃ©nez, CantÃ³n GuÃ¡cimo, Provincia LimÃ³n, 70604, Costa Rica university 10.21990825 -83.59177371174943  Costa Rica OSM 0.330362\n",
      "  *   earth, Chaloupky, okres Beroun, StÅ™ednÃ­ ÄŒechy, 267 62, ÄŒesko track 49.7933447 13.8667052  ÄŒesko OSM 0.21\n",
      "  *   earth, MiliÄÃ­n, okres BeneÅ¡ov, StÅ™ednÃ­ ÄŒechy, 257 86, ÄŒesko track 49.5904859 14.6651358  ÄŒesko OSM 0.21\n",
      "  *   earth, KlÃ¡Å¡ter u VilÃ©mova, VilÃ©mov, okres HavlÃ­ÄkÅ¯v Brod, Kraj VysoÄina, JihovÃ½chod, 582 83, ÄŒesko track 49.802872 15.5172618  ÄŒesko OSM 0.21\n",
      "looking for south-east\n",
      "  *   South-East District, Botswana administrative -24.9902332 25.726402352052464  Botswana OSM 0.587421\n",
      "  *   DÃ©partement du Sud-Est, Ayiti administrative 18.2973566 -72.3745698  Ayiti OSM 0.460338\n",
      "  *   Sud-Est, RomÃ¢nia administrative 44.97028655 28.282042663820434  RomÃ¢nia OSM 0.381902\n",
      "  *   South East Constituency 1947, Dublin, DÃºn Laoghaire-Rathdown, Dublin 4, Leinster, Ã‰ire / Ireland political 53.3262506 -6.236059861357543  Ã‰ire / Ireland OSM 0.325\n",
      "  *   South East, York Springs, Adams County, Pennsylvania, 17372, United States residential 40.006443 -77.113805  United States OSM 0.3\n",
      "looking for Ladybird\n",
      "  *   Ladybird, 70, Upper Street, Angel, Highbury, London Borough of Islington, London, Greater London, England, N1 2XQ, United Kingdom bar 51.5360577 -0.1038735  United Kingdom OSM 0.1101\n",
      "  *   Ladybird, Place Louis Barthou, Saint-GenÃ¨s, Nansouty - Saint-GenÃ¨s, Bordeaux, Gironde, Nouvelle-Aquitaine, France mÃ©tropolitaine, 33000, France convenience 44.8216508 -0.5827753  France OSM 0.1101\n",
      "  *   Ladybird, Fore Street, Redruth, Cornwall, England, TR15 2AL, United Kingdom gift 50.233202399999996 -5.228724001225023  United Kingdom OSM 0.1101\n",
      "  *   Ladybird, George Varghese Lane, Elamkulam, Ernakulam, Kanayannur, Ernakulam district, Kerala, 682020, India tailor 9.9642514 76.3020845  India OSM 0.1101\n",
      "  *   Ladybird, London Street, Lyttelton, Banks Peninsula Community, Christchurch City, Canterbury, 8082, New Zealand / Aotearoa clothes -43.6020782 172.7198237  New Zealand / Aotearoa OSM 0.1101\n",
      "looking for Commandant\n",
      "looking for Port Arthur\n",
      "  *   Port Arthur, Jefferson County, Texas, United States administrative 29.8988618 -93.9288723  United States OSM 0.738362\n",
      "  *   Port Arthur, Tasman, Tasmania, 7182, Australia administrative -43.1435301 147.8440404  Australia OSM 0.603317\n",
      "  *   å¤§è¿žå¸‚, é’æ³¥æ´¼æ¡¥è¡—é“, ä¸­å±±åŒº, å¤§è¿žå¸‚, è¾½å®çœ, 116001, ä¸­å›½ city 38.9181714 121.6282945  ä¸­å›½ OSM 0.579541\n",
      "  *   Port Arthur, Keskusta, Turku, Turun seutukunta, Varsinais-Suomi, Lounais-Suomen aluehallintovirasto, Manner-Suomi, 20100, Suomi / Finland suburb 60.4468775 22.2444076  Suomi / Finland OSM 0.475\n",
      "  *   Port Arthur, Thunder Bay, Thunder Bay District, Northwestern Ontario, Ontario, P7A 4K9, Canada suburb 48.4348261 -89.2194423  Canada OSM 0.475\n",
      "looking for Arthur\n",
      "  *   Arthur County, Nebraska, 69121, United States administrative 41.5721288 -101.6974898  United States OSM 0.591617\n",
      "  *   Arthur, Ida County, Iowa, United States administrative 42.3353 -95.3475647  United States OSM 0.541109\n",
      "  *   Arthur, Douglas County, Illinois, United States administrative 39.7147552 -88.472278  United States OSM 0.535988\n",
      "  *   Arthur, Cass County, North Dakota, United States administrative 47.1041435 -97.2181431  United States OSM 0.509001\n",
      "  *   Arthur, Arthur County, Nebraska, 69121, United States administrative 41.5706962 -101.6914885  United States OSM 0.462959\n",
      "looking for Hells Gates\n",
      "  *   Hells Gates, New South Wales, 2898, Australia bay -31.518396 159.0721965  Australia OSM 0.4\n",
      "  *   Hells Gates, Tasmania, Australia strait -42.2101271 145.2142261  Australia OSM 0.4\n",
      "  *   Hells Gates, Douglas Parish, York County / ComtÃ© d'York, New Brunswick / Nouveau-Brunswick, Canada water 46.2939985 -66.8910642  Canada OSM 0.4\n",
      "looking for England\n",
      "  *   England, United Kingdom administrative 52.5310214 -1.2649062  United Kingdom OSM 0.948749\n",
      "  *   Worcester, Worcestershire, England, United Kingdom administrative 52.1911849 -2.2206585  United Kingdom OSM 0.656443\n",
      "  *   England, Lonoke County, Arkansas, United States administrative 34.5442609 -91.9690285  United States OSM 0.499785\n",
      "  *   England, Nordstrand, Nordsee-Treene, Nordfriesland, Schleswig-Holstein, 25845, Deutschland neighbourhood 54.495797 8.8784857  Deutschland OSM 0.36\n",
      "  *   England, Montgomery Township, Ashland County, Ohio, United States hamlet 40.8403347 -82.2393255  United States OSM 0.36\n",
      "looking for New Town\n",
      "  *   New Town, New Town/Broughton, City of Edinburgh, Alba / Scotland, EH3 6HU, United Kingdom suburb 55.9554575 -3.1989995  United Kingdom OSM 0.653699\n",
      "  *   New Town, Shell Creek Segment, Mountrail County, North Dakota, 58763, United States administrative 47.980848 -102.49018  United States OSM 0.619111\n",
      "  *   New Town, Hobart, City of Hobart, Tasmania, 7008, Australia administrative -42.8588009 147.3058753  Australia OSM 0.519711\n",
      "  *   New Town, Copper Coast Council, South Australia, 5554, Australia administrative -33.9557061 137.69672510873852  Australia OSM 0.5\n",
      "  *   New Town, Rajarhat, North 24 Parganas, West Bengal, 700161, India town 22.5882834 88.4734476  India OSM 0.5\n",
      "looking for verandah.-She\n",
      "looking for Grummet Island\n",
      "looking for Grummet\n",
      "  *   Grummet, Ahlstadt, Meeder, Landkreis Coburg, Bayern, 96484, Deutschland locality 50.3686748 10.8561277  Deutschland OSM 0.235\n",
      "  *   grummet, S 311, Reuth, Weischlitz, Vogtlandkreis, Sachsen, 08538, Deutschland information 50.4723087 11.96739  Deutschland OSM 0.1001\n",
      "looking for Malabar\n",
      "  *   Malabar, Brevard County, Florida, 32950, United States administrative 27.9869722 -80.5870164  United States OSM 0.486253\n",
      "  *   Malabar, Jawa Barat, Indonesia volcano -7.1404971 107.6313311  Indonesia OSM 0.47818\n",
      "  *   Malabar, Sydney, Randwick City Council, New South Wales, 2036, Australia administrative -33.9629779 151.2480171  Australia OSM 0.418817\n",
      "  *   Malabar, Cilacap, Jawa Tengah, Indonesia village -7.2880681 108.6960653  Indonesia OSM 0.385\n",
      "  *   Malabar, Lengkong, Jawa Barat, 40285, Indonesia village -6.9260791 107.6210172  Indonesia OSM 0.385\n",
      "looking for Dawes\n",
      "  *   Dawes County, Nebraska, United States administrative 42.71723 -103.1216528  United States OSM 0.590549\n",
      "  *   Dawes, Mendocino County, California, United States isolated_dwelling 38.9490664 -123.085002  United States OSM 0.470685\n",
      "  *   Dawes, Kanawha County, West Virginia, 25054, United States hamlet 38.1428826 -81.4520584  United States OSM 0.450547\n",
      "  *   Dawes, Mobile County, Alabama, 36695, United States hamlet 30.6076926 -88.2552828  United States OSM 0.36\n",
      "  *   Dawes, Ottawa County, Oklahoma, United States hamlet 36.8814607 -94.9913489  United States OSM 0.36\n",
      "looking for Sydney\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *   Sydney, Council of the City of Sydney, New South Wales, Australia administrative -33.8698439 151.2082848  Australia OSM 0.834591\n",
      "  *   Sydney, Stutsman County, North Dakota, United States village 46.731338 -98.7682161  United States OSM 0.834591\n",
      "  *   Sydney (Kingsford Smith) Airport, Centre Road, Mascot, Sydney, Bayside Council, New South Wales, 2020, Australia aerodrome -33.9498935 151.18196819346016  Australia OSM 0.607871\n",
      "  *   Sydney, Cape Breton Regional Municipality, Cape Breton County, Nova Scotia, Canada administrative 46.137977 -60.194092  Canada OSM 0.575817\n",
      "  *   Sydney, Council of the City of Sydney, New South Wales, 2000, Australia administrative -33.867926 151.21013810170962  Australia OSM 0.574845\n"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "# For every placename in our list\n",
    "for p in geolocdata:\n",
    "    # Already found a location, so skip to the next placename\n",
    "    if len(p['locations']['best_match']) > 0:\n",
    "        continue\n",
    "        \n",
    "    placename = p['placename']\n",
    "    print (\"looking for\",placename)\n",
    "\n",
    "    # query the OSM database\n",
    "    url = f\"https://nominatim.openstreetmap.org/search?q={placename}&format=json&limit={limit}\"\n",
    "    response = osm_call_api(url)\n",
    "    response_dict = json.loads(response.text)\n",
    "    #print(response.text)\n",
    "\n",
    "    p['locations']['candidates']=None\n",
    "    \n",
    "    # Handle no results found\n",
    "    if len(response_dict) is 0:\n",
    "        # skip to the next placename\n",
    "        continue\n",
    "        \n",
    "    # Save the possible locations for later processing\n",
    "\n",
    "    # Handle results found\n",
    "    for response_record in response_dict:\n",
    "        #  Use this to look at a reduced set of data from the results\n",
    "        #print(response_record)\n",
    "        cleaned_response = osm_format_response(response_record)\n",
    "        #print(\"   ...... \",cleaned_data)\n",
    "\n",
    "        # Add the data to a dataframe\n",
    "        df = pd.DataFrame(columns = [#'name' , \n",
    "                                     'Location',\n",
    "                                     \"Category\",\n",
    "                                     \"Latitude\",\n",
    "                                     \"Longitude\",\n",
    "                                     \"PartOf\",\n",
    "                                     \"Gazetteer\",\n",
    "                                     \"Certainity\"])\n",
    "        df = df.append({#\"name\": placename, \n",
    "                        \"Location\": cleaned_response[\"Name\"],\n",
    "                        \"Category\": cleaned_response[\"Type\"],\n",
    "                        'Latitude': cleaned_response[\"Latitude\"],\n",
    "                        'Longitude': cleaned_response[\"Longitude\"],\n",
    "                        'PartOf': cleaned_response[\"PartOf\"],\n",
    "                        'Gazetteer': cleaned_response[\"Gazetteer\"],\n",
    "                        'Certainity': cleaned_response[\"Importance\"]}, \n",
    "                       ignore_index=True)\n",
    "        data_frames.append(df)\n",
    "        \n",
    "        # print the output\n",
    "        matchdata = df.to_string(index=False,header=False)\n",
    "        print(\"  *  \",matchdata)\n",
    "\n",
    "\n",
    "        #print(df)\n",
    "\n",
    "    # add the results to the geoloc dataframe\n",
    "    # review the outcomes later\n",
    "    p['locations']['candidates'] = data_frames\n",
    "\n",
    "    #print(p)\n",
    "        \n",
    "    #exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What placenames have you still not found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the sleepy sea',\n",
       " \"Julia Vickers's\",\n",
       " 'the Hydaspes for Calcutta',\n",
       " 'the poop guard',\n",
       " 'MONOTONY',\n",
       " 'the Three Thumbs',\n",
       " 'Storing Island',\n",
       " 'Commandant',\n",
       " 'verandah.-She',\n",
       " 'Grummet Island']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatcheddata = [p['placename'] for p in geolocdata \n",
    "             if len(p['locations']['best_match'])==0 and p['locations']['candidates']==None]\n",
    "unmatcheddata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where have you found locations for placenames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the Bay of Biscay',\n",
       " 'Heath',\n",
       " 'London',\n",
       " \"Van Diemen's Land\",\n",
       " 'Vickers',\n",
       " 'Sylvia',\n",
       " 'Bath',\n",
       " 'Frere',\n",
       " 'Chatham',\n",
       " 'CHAPTER II',\n",
       " 'Surgeon Pine',\n",
       " 'Coromandel',\n",
       " 'Pine',\n",
       " 'India',\n",
       " \"Three'll\",\n",
       " \"Van Diemen's\",\n",
       " 'Tasman',\n",
       " 'Cape Pillar',\n",
       " \"Pirates' Bay\",\n",
       " 'east',\n",
       " 'west',\n",
       " 'the Isle of Wight',\n",
       " 'the South-West Cape',\n",
       " 'Swan Port',\n",
       " 'Mediterranean',\n",
       " 'Maria Island',\n",
       " 'Peninsula',\n",
       " 'Storm Bay',\n",
       " 'Italy',\n",
       " 'Sorrell',\n",
       " 'Bruny Island',\n",
       " 'Mount Royal',\n",
       " \"D'Entrecasteaux Channel\",\n",
       " 'Actaeon',\n",
       " 'the South Cape',\n",
       " 'New Norfolk',\n",
       " 'Derwent',\n",
       " 'the Southern Ocean',\n",
       " 'Tamar',\n",
       " 'Victoria',\n",
       " 'Port Philip Bay',\n",
       " 'Wellington',\n",
       " 'Dromedary',\n",
       " 'Mount Wellington',\n",
       " 'Launceston',\n",
       " 'Smyrna',\n",
       " 'Pyramid Island',\n",
       " 'Rocky Point',\n",
       " 'Port Davey',\n",
       " 'Mount Direction',\n",
       " 'Macquarie Harbour',\n",
       " 'Mount Heemskirk',\n",
       " 'Mount Zeehan',\n",
       " \"King's River\",\n",
       " 'Sarah Island',\n",
       " \"Philip's Island\",\n",
       " 'Hobart Town',\n",
       " 'earth',\n",
       " 'south-east',\n",
       " 'Ladybird',\n",
       " 'Port Arthur',\n",
       " 'Honduras',\n",
       " 'Arthur',\n",
       " 'Hells Gates',\n",
       " 'England',\n",
       " 'New Town',\n",
       " 'Grummet',\n",
       " 'Malabar',\n",
       " 'Dawes',\n",
       " 'Sydney']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchdata = [p['placename'] for p in geolocdata \n",
    "             if len(p['locations']['best_match'])>0 or p['locations']['candidates']!=None]\n",
    "matchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
